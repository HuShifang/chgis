{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#! /usr/bin/python3\n",
    "\n",
    "# Script for comparing an input .csv file with an existing .csv file (e.g. the current CHGIS).\n",
    "# Indicates 1) matches on name and 2) strength of match on content\n",
    "# Requires the library 'pandas' to be installed, which is included in Anaconda's free Python distribution\n",
    "\n",
    "# by Stephen Ford (stephen.p.ford@gmail.com)\n",
    "\n",
    "import pandas as pd\n",
    "import os.path\n",
    "\n",
    "# suppressing SettingWithCopyWarning\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# function for selecting .csv files for manipulation\n",
    "\n",
    "def csv_picker():\n",
    "    ''' Function for checking whether user input path 1) is that of a valid file, and 2) is of a file ending with '.csv'\n",
    "        Prompts for re-entry if entry is invalid.\n",
    "        Returns a pandas DataFrame constructed from the valid .csv file\n",
    "    '''\n",
    "    name = input()\n",
    "\n",
    "    # checking that the path is a valid filename, and prompting for re-entry if not\n",
    "    while not (os.path.isfile(name)):\n",
    "        print(\"Not a valid filename.  Please try again:\")\n",
    "        name = input()\n",
    "        \n",
    "    # checking that the valid filename ends in .csv, prompting for re-entry if not\n",
    "    while not name.endswith('.csv'):\n",
    "        print(\"Filename does not end in .csv -- please try again:\")\n",
    "        name = input()\n",
    "\n",
    "    print(\"\\nThank you -- filename %s is valid.\\n\" % name)       \n",
    "    return pd.read_csv(name, low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please input the path of the .csv file (with extension) you wish to compare with the CHGIS:\n",
      "/home/sf/chgis/input/sample_data/lexdata.txt.data.csv\n",
      "\n",
      "Thank you -- filename /home/sf/chgis/input/sample_data/lexdata.txt.data.csv is valid.\n",
      "\n",
      "Please input the path of the .csv file (with extension) containing CHGIS data (script expects v5, or at least its column names):\n",
      "/home/sf/chgis/input/v5_augment_2016-08-09.csv\n",
      "\n",
      "Thank you -- filename /home/sf/chgis/input/v5_augment_2016-08-09.csv is valid.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# soliciting files for comparison; presumption is that second file entered will be the CHGIS v5 in .csv format\n",
    "print(\"Please input the path of the .csv file (with extension) you wish to compare with the CHGIS:\")\n",
    "new_data = csv_picker()\n",
    "# /home/sf/chgis/input/sample_data/Donghan_2014-10-02_copy.csv\n",
    "# /home/sf/chgis/input/sample_data/lexdata.txt.data.csv\n",
    "\n",
    "print(\"Please input the path of the .csv file (with extension) containing CHGIS data (script expects v5, or at least its column names):\")\n",
    "chgis = csv_picker()\n",
    "# /home/sf/chgis/input/v5_augment_2016-08-09.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initializing list of input_fields (i.e. normalized input fields, called \"input_*\" in final output)\n",
    "input_fields = []\n",
    "\n",
    "# function for mapping the input .csv's fields to the desired, standardized output fields\n",
    "def field_mapper(normalized_field, frame=new_data, fields=input_fields):\n",
    "    ''' Function that will prompt user to manually map fields of the input .csv to standardized output fields.\n",
    "        Name changes will be made in-place (i.e. in the DataFrame -- the .csv will be untouched).\n",
    "        If user fails to enter anything for the given mapping, the output field will be present in the output \n",
    "        file, but have no values.        \n",
    "    '''\n",
    "    \n",
    "    print(\"\\nPlease enter the field in the incoming non-CHGIS .csv that will be labeled '%s' in the output .csv:\" % normalized_field)\n",
    "    orig_field = input()\n",
    "    \n",
    "    # prompts for re-entering the input field if 1) it is not one of the column names and 2) it isn't an empty string\n",
    "    while (not orig_field in list(new_data.columns.values)) and (orig_field):\n",
    "        print(\"\\nNot a valid column name.  Please try again:\")\n",
    "        orig_field = input()\n",
    "        \n",
    "    # simply exit if the user pressed enter, bypassing the mapping, or perform the mapping if a valid field name has been entered\n",
    "    if orig_field:\n",
    "        frame.rename(columns={orig_field:normalized_field}, inplace=True)\n",
    "        fields += [normalized_field]\n",
    "    return fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# declaring the list of output .csv field names that will derive from the new data\n",
    "# i.e., all those fields whose names will be 'input_*' in the final .csv\n",
    "\n",
    "normalized_fields = [   \n",
    "    'input_id',\n",
    "    'input_nm_py',\n",
    "    'input_nm_simp',\n",
    "    'input_nm_trad',\n",
    "    'input_type',\n",
    "    'input_year_beg',\n",
    "    'input_year_end',\n",
    "    'input_dynasty',\n",
    "    'input_other_id',\n",
    "    'input_prnt',\n",
    "    'input_obj_type',\n",
    "    'input_x_coord',\n",
    "    'input_y_coord'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Please enter the field in the incoming non-CHGIS .csv that will be labeled 'input_id' in the output .csv:\n",
      "id\n",
      "\n",
      "Please enter the field in the incoming non-CHGIS .csv that will be labeled 'input_nm_py' in the output .csv:\n",
      "\n",
      "\n",
      "Please enter the field in the incoming non-CHGIS .csv that will be labeled 'input_nm_simp' in the output .csv:\n",
      "name\n",
      "\n",
      "Please enter the field in the incoming non-CHGIS .csv that will be labeled 'input_nm_trad' in the output .csv:\n",
      "\n",
      "\n",
      "Please enter the field in the incoming non-CHGIS .csv that will be labeled 'input_type' in the output .csv:\n",
      "level\n",
      "\n",
      "Please enter the field in the incoming non-CHGIS .csv that will be labeled 'input_year_beg' in the output .csv:\n",
      "start\n",
      "\n",
      "Please enter the field in the incoming non-CHGIS .csv that will be labeled 'input_year_end' in the output .csv:\n",
      "end\n",
      "\n",
      "Please enter the field in the incoming non-CHGIS .csv that will be labeled 'input_dynasty' in the output .csv:\n",
      "dynasty\n",
      "\n",
      "Please enter the field in the incoming non-CHGIS .csv that will be labeled 'input_other_id' in the output .csv:\n",
      "oldid\n",
      "\n",
      "Please enter the field in the incoming non-CHGIS .csv that will be labeled 'input_prnt' in the output .csv:\n",
      "Shu\n",
      "\n",
      "Please enter the field in the incoming non-CHGIS .csv that will be labeled 'input_obj_type' in the output .csv:\n",
      "\n",
      "\n",
      "Please enter the field in the incoming non-CHGIS .csv that will be labeled 'input_x_coord' in the output .csv:\n",
      "JingDu\n",
      "\n",
      "Please enter the field in the incoming non-CHGIS .csv that will be labeled 'input_y_coord' in the output .csv:\n",
      "WeuDu\n"
     ]
    }
   ],
   "source": [
    "# renaming fields in the new data DataFrame to conform to specifications\n",
    "\n",
    "for field in normalized_fields:\n",
    "    input_fields = field_mapper(field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# storing to avoid having to reenter stuff later\n",
    "#han_new_data = new_data\n",
    "#han_input_fields = input_fields\n",
    "#han_chgis = chgis\n",
    "\n",
    "lex_new_data = new_data\n",
    "lex_input_fields = input_fields\n",
    "lex_chgis = chgis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# only execute to restore from stored data\n",
    "#new_data = han_new_data\n",
    "#input_fields = han_input_fields\n",
    "#chgis = han_chgis\n",
    "\n",
    "new_data = lex_new_data\n",
    "input_fields = lex_input_fields\n",
    "chgis = lex_chgis\n",
    "output_fields = []\n",
    "tgaz_fields = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# dropping all fields from the new_data DataFrame that won't be in final output\n",
    "new_data = new_data[input_fields]\n",
    "\n",
    "# dropping fields from the new_data DataFrame that weren't mapped\n",
    "#for field in new_data.columns:\n",
    "#    if new_data[field].empty:\n",
    "#        new_data.drop(field, inplace=True)\n",
    "#        input_fields.remove(field)\n",
    "        \n",
    "#print(\"input_fields are: %s\" % str(input_fields))\n",
    "#print(\"new_data cols are: %s\" % str(new_data.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# manually renaming one exception to the following pattern\n",
    "chgis.rename(columns={'src':'data_source'}, inplace=True)\n",
    "\n",
    "# renaming the CHGIS fields in-place to conform to output specifications\n",
    "chgis.columns = ['tgaz_%s' % x for x in chgis.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# offering user choice of strict or fuzzy name-matching\n",
    "\n",
    "def merge_chooser():\n",
    "    ''' Function called only if the user selects to merge on traditional characters 繁體字 or simplified characters 简体字\n",
    "        Lets user choose whether to do a strict or fuzzy merge.\n",
    "        In a fuzzy merge, only the first two characters of the Chinese names will be checked against one another.\n",
    "    '''\n",
    "    print(\n",
    "    '''\n",
    "Please indicate, by entering a numerical digit 1-2, whether you wish to do a strict or fuzzy match of names:\n",
    "    1. Strict matching (e.g. '張掖' matches '張掖', but '張掖' does not match '張掖居延屬國')\n",
    "    2. Fuzzy matching (e.g. '張掖' matches '張掖', and '張掖' also matches '張掖居延屬國')\n",
    "    ''')\n",
    "\n",
    "    accepted = False\n",
    "    choice = input()\n",
    "\n",
    "    while accepted == False:\n",
    "        if choice == '1':\n",
    "            print('Proceeding with strict matching of names.')\n",
    "            accepted = True\n",
    "            mode = 'strict'\n",
    "            df = chgis.merge(new_data, how='outer', left_on=chgis_name_match_field, right_on=input_name_match_field, indicator=True)\n",
    "            return df, mode\n",
    "        elif choice == '2':\n",
    "            print('Proceeding with fuzzy matching of names.')\n",
    "            accepted = True\n",
    "            mode = 'fuzzy'\n",
    "            chgis['fuzzy_nm'] = chgis[chgis_name_match_field].map(lambda x: x[:2])\n",
    "            new_data['fuzzy_nm'] = new_data[input_name_match_field].map(lambda x: x[:2])\n",
    "            df = chgis.merge(new_data, how='outer', on='fuzzy_nm', indicator=True)\n",
    "            return df, mode\n",
    "        else:\n",
    "            print(\"\\nNot a valid response.  Please try again:\\n\")\n",
    "            choice = input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initializing list of tgaz fields\n",
    "tgaz_fields = [\n",
    "    'tgaz_sys_id',\n",
    "    'tgaz_nm_py',\n",
    "    'tgaz_nm_simp',\n",
    "    'tgaz_nm_trad',\n",
    "    'tgaz_beg',\n",
    "    'tgaz_end',\n",
    "    'tgaz_data_source',\n",
    "    'tgaz_obj_type',\n",
    "    'tgaz_pres_loc',\n",
    "    'tgaz_prnt_id',\n",
    "    'tgaz_prnt_py',\n",
    "    'tgaz_prnt_simp',\n",
    "    'tgaz_prnt_sysid',\n",
    "    'tgaz_type_ch',\n",
    "    'tgaz_type_py',\n",
    "    'tgaz_x_coord',\n",
    "    'tgaz_y_coord'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Thank you. Now, please indicate, by entering a numerical digit 1-3, which of the following names you wish to make the primary key for comparing data:\n",
      "    1. Name in complex/traditional Chinese characters 繁体字\n",
      "    2. Name in simplified Chinese characters 简体字\n",
      "    3. Name in pinyin 拼音\n",
      "    \n",
      "2\n",
      "\n",
      "Using name in simplified Chinese characters 简体字 as primary matching key.\n",
      "\n",
      "Please indicate, by entering a numerical digit 1-2, whether you wish to do a strict or fuzzy match of names:\n",
      "    1. Strict matching (e.g. '張掖' matches '張掖', but '張掖' does not match '張掖居延屬國')\n",
      "    2. Fuzzy matching (e.g. '張掖' matches '張掖', and '張掖' also matches '張掖居延屬國')\n",
      "    \n",
      "2\n",
      "Proceeding with fuzzy matching of names.\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'tgaz_nm_simp'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/home/sf/anaconda3/lib/python3.5/site-packages/pandas/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   1944\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1945\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1946\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas/index.c:4154)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas/index.c:4018)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/hashtable.pyx\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas/hashtable.c:12368)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/hashtable.pyx\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas/hashtable.c:12322)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'tgaz_nm_simp'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-5a277c9b0c02>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[0mchgis_name_match_field\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'tgaz_nm_simp'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[1;31m#output_name_match_field = 'out_nm_simp_match'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m         \u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname_mode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmerge_chooser\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m         \u001b[1;31m#output_fields = [output_name_match_field]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchoice\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'3'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'input_nm_py'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minput_fields\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-25-82ee4a657367>\u001b[0m in \u001b[0;36mmerge_chooser\u001b[1;34m()\u001b[0m\n\u001b[0;32m     27\u001b[0m             \u001b[0maccepted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m             \u001b[0mmode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'fuzzy'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m             \u001b[0mchgis\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'fuzzy_nm'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mchgis\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mchgis_name_match_field\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m             \u001b[0mnew_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'fuzzy_nm'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0minput_name_match_field\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m             \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mchgis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'outer'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'fuzzy_nm'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindicator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/sf/anaconda3/lib/python3.5/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1995\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1996\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1997\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1998\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1999\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/sf/anaconda3/lib/python3.5/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2002\u001b[0m         \u001b[1;31m# get column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2003\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2004\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2005\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2006\u001b[0m         \u001b[1;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/sf/anaconda3/lib/python3.5/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m   1348\u001b[0m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1349\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1350\u001b[1;33m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1351\u001b[0m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1352\u001b[0m             \u001b[0mcache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/sf/anaconda3/lib/python3.5/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, item, fastpath)\u001b[0m\n\u001b[0;32m   3288\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3289\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3290\u001b[1;33m                 \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3291\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3292\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/sf/anaconda3/lib/python3.5/site-packages/pandas/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   1945\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1946\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1947\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1948\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1949\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas/index.c:4154)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas/index.c:4018)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/hashtable.pyx\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas/hashtable.c:12368)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/hashtable.pyx\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas/hashtable.c:12322)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'tgaz_nm_simp'"
     ]
    }
   ],
   "source": [
    "# soliciting user choice regarding which name field to take as primary\n",
    "#print(input_fields)\n",
    "\n",
    "print(\n",
    "    '''\n",
    "Thank you. Now, please indicate, by entering a numerical digit 1-3, which of the following names you wish to make the primary key for comparing data:\n",
    "    1. Name in complex/traditional Chinese characters 繁体字\n",
    "    2. Name in simplified Chinese characters 简体字\n",
    "    3. Name in pinyin 拼音\n",
    "    '''\n",
    ")\n",
    "\n",
    "accepted = False\n",
    "choice = input()\n",
    "\n",
    "while accepted == False:\n",
    "    if ((choice == '1') and ('input_nm_trad' in input_fields)):\n",
    "        print(\"\\nUsing name in complex/traditional Chinese characters 繁体字 as primary matching key.\")\n",
    "        accepted = True\n",
    "        input_name_match_field = 'input_nm_trad'\n",
    "        chgis_name_match_field = 'tgaz_nm_trad'\n",
    "        #output_name_match_field = 'out_nm_trad_match'\n",
    "        df, name_mode = merge_chooser()\n",
    "    elif ((choice == '2') and ('input_nm_simp' in input_fields)):\n",
    "        print(\"\\nUsing name in simplified Chinese characters 简体字 as primary matching key.\")\n",
    "        accepted = True\n",
    "        input_name_match_field = 'input_nm_simp'\n",
    "        chgis_name_match_field = 'tgaz_nm_simp'\n",
    "        #output_name_match_field = 'out_nm_simp_match'\n",
    "        df, name_mode = merge_chooser()\n",
    "        #output_fields = [output_name_match_field]\n",
    "    elif ((choice == '3') and ('input_nm_py' in input_fields)):\n",
    "        print(\"\\nUsing name in pinyin 拼音 as primary matching key.\")\n",
    "        accepted = True\n",
    "        input_name_match_field = 'input_nm_py'\n",
    "        chgis_name_match_field = 'tgaz_nm_py'\n",
    "        #output_name_match_field = 'out_nm_py_match'\n",
    "        name_mode = 'strict'\n",
    "        print('Fuzzy matching is not currently supported for pinyin names.  Proceeding with strict matching.')\n",
    "        df = chgis.merge(new_data, how='outer', left_on=chgis_name_match_field, right_on=input_name_match_field, indicator=True)\n",
    "        #df[output_name_match_field] = \n",
    "        #output_fields = []\n",
    "        \n",
    "    else:\n",
    "        print(\"\\nNot a valid response.  Please try again, entering a choice corresponding to a valid field:\\n\")\n",
    "        choice = input()\n",
    "        \n",
    "output_fields = [] # OR [output_name_match_field]                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#### Abandoning comprehensive for-loop for sake of year matching; manually stringifying coords instead\n",
    "\n",
    "# converting all fields to strings for ease of comparison\n",
    "#for field in list(df.columns):\n",
    "#    df[field] = df[field].astype(str)\n",
    "spatial_coords = ['input_x_coord', 'input_y_coord', 'tgaz_x_coord', 'tgaz_y_coord']\n",
    "for field in spatial_coords:\n",
    "    if (field in input_fields) or (field in tgaz_fields):\n",
    "        df[field] = df[field].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# removing rows that are only present in the CHGIS file\n",
    "df = df[df['_merge'] != 'left_only']\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def coordinate_matcher(coords, frame=df, fields=output_fields):\n",
    "    print(\n",
    "        '''\n",
    "    Please indicate, by entering a numerical digit 1-2, whether you wish to do a strict or fuzzy match of spatial coordinates:\n",
    "        1. Strict matching (requires exact match, e.g. '119.64656' does NOT match '119.646560', '119.64657', or '119.325')\n",
    "        2. Fuzzy matching (only requires that truncated number of whole degrees matches, e.g. '119.64656' DOES match '119.646560', '119.64657', and '119.325')\n",
    "        ''')\n",
    "\n",
    "    accepted = False\n",
    "    choice = input()\n",
    "\n",
    "    while accepted == False:\n",
    "        if choice == '1':\n",
    "            print('Proceeding with strict matching of spatial coordinates.')\n",
    "            accepted = True\n",
    "            for coord in coords:\n",
    "                frame['out_%s_coord_match' % coord] = frame['input_%s_coord' % coord] == frame['tgaz_%s_coord' % coord]\n",
    "                fields += ['out_%s_coord_match' % coord]\n",
    "            return \"strict\"\n",
    "        elif choice == '2':\n",
    "            print(\"Proceeding with fuzzy matching of spatial coordinates.\")\n",
    "            accepted = True\n",
    "            for coord in coords:\n",
    "                frame['fuzzy_out_%s_coord_match' % coord] = frame['input_%s_coord' % coord].map(lambda x: x[:3]) == frame['tgaz_%s_coord' % coord].map(lambda x: x[:3])\n",
    "                fields += ['fuzzy_out_%s_coord_match' % coord]\n",
    "            return \"fuzzy\" \n",
    "        else:\n",
    "            print(\"\\nNot a valid response.  Please try again:\\n\")\n",
    "            choice = input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Please indicate, by entering a numerical digit 1-2, whether you wish to do a strict or fuzzy match of spatial coordinates:\n",
      "        1. Strict matching (requires exact match, e.g. '119.64656' does NOT match '119.646560', '119.64657', or '119.325')\n",
      "        2. Fuzzy matching (only requires that truncated number of whole degrees matches, e.g. '119.64656' DOES match '119.646560', '119.64657', and '119.325')\n",
      "        \n",
      "2\n",
      "Proceeding with fuzzy matching of spatial coordinates.\n"
     ]
    }
   ],
   "source": [
    "if ('input_x_coord' in input_fields) and ('input_y_coord' in input_fields):\n",
    "    coord_mode = coordinate_matcher(['x', 'y'])\n",
    "elif ('input_x_coord' in input_fields) and not ('input_y_coord' in input_fields):\n",
    "    coord_mode = coordinate_matcher(['x'])\n",
    "elif not ('input_x_coord' in input_fields) and ('input_y_coord' in input_fields):\n",
    "    coord_mode = coordinate_matcher(['y'])\n",
    "else:\n",
    "    print(\"\\nNo spatial coordinate fields available for matching.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "############## NEW ################\n",
    "#if (df['input_year_beg'].empty() | df['input_year_end'].empty()):\n",
    "#    if (df['input_year_beg'].empty()):\n",
    "#        df.drop(['input_year_beg'])\n",
    "#        input_fields.remove('input_year_beg')\n",
    "#        beg_year_matching = False\n",
    "#    if (df['input_year_end'].empty()):\n",
    "#        df.drop(['input_year_end'])\n",
    "#        input_fields.remove('input_year_end')\n",
    "#        end_year_matching = False\n",
    "\n",
    "if (not 'input_year_beg' in input_fields) or (not 'input_year_end' in input_fields):\n",
    "    print(\"Incoming data lacks a beginning and/or ending year field; no date comparisons will be made.\")\n",
    "else:\n",
    "    # beg_year_matching, end_year_matching = True, True\n",
    "    \n",
    "    year_fields = ['input_year_beg', 'input_year_end', 'tgaz_beg', 'tgaz_end']\n",
    "    \n",
    "    #for field in year_fields:\n",
    "    #    print(df[field].dtype)\n",
    "           \n",
    "    # overlap field initialization\n",
    "    df['out_year_overlap'] = ''\n",
    "\n",
    "           \n",
    "    # converting to type float64 (invalid years become 'NaN', and pandas.isnull(<Series_(column)>) returns True for those values\n",
    "    for year_field in year_fields:\n",
    "        df[year_field] = pd.to_numeric(df[year_field], errors='coerce')\n",
    "    \n",
    "    # in-row match testing\n",
    "    df['out_beg_match'] = df['input_year_beg'] == df['tgaz_beg']\n",
    "    df['out_end_match'] = df['input_year_end'] == df['tgaz_end']\n",
    "    \n",
    "    # testing for timespan relationships\n",
    "    df['out_year_overlap'][((df['input_year_beg'] == (df['tgaz_end'] + 1)) | (df['input_year_end'] == (df['tgaz_beg'] - 1)))] = 'adjacent'\n",
    "    df['out_year_overlap'][(df['input_year_beg'] > df['tgaz_beg']) & (df['input_year_end'] < df['tgaz_end'])] = 'new_nested_in_chgis'\n",
    "    df['out_year_overlap'][(df['input_year_beg'] < df['tgaz_beg']) & (df['input_year_end'] > df['tgaz_end'])] = 'chgis_nested_in_new'\n",
    "    df['out_year_overlap'][(df['input_year_beg'] < df['tgaz_beg']) & (df['input_year_end'] > df['tgaz_beg']) & (df['input_year_end'] < df['tgaz_end'])] = 'partial_incl_start'\n",
    "    df['out_year_overlap'][(df['input_year_beg'] > df['tgaz_beg']) & (df['input_year_beg'] < df['tgaz_end']) & (df['input_year_end'] > df['tgaz_end'])] = 'partial_incl_end'\n",
    "    df['out_year_overlap'][(df['input_year_beg'] == df['tgaz_beg']) & (df['input_year_end'] == df['tgaz_end'])] = 'perfect_match'\n",
    "    df['out_year_overlap'][(df['input_year_beg'] == 0) | (df['input_year_end'] == 0) | (df['tgaz_beg'] == 0) | (df['tgaz_end'] == 0)] = 'CAUTION__ZEROES'\n",
    "    df['out_year_overlap'][(df['input_year_beg'] > df['input_year_end']) | (df['tgaz_beg'] > df['tgaz_end'])] = 'ERROR__END_BEFORE_BEG'\n",
    "    df['out_year_overlap'][(df['_merge'] == 'both') & (pd.isnull(df['input_year_beg']) | pd.isnull(df['input_year_end']) | pd.isnull(df['tgaz_beg']) | pd.isnull(df['tgaz_end']))] = 'ERROR__NON_NUMERIC_YEAR_VALUE'\n",
    "    \n",
    "    # updating output fields\n",
    "    output_fields += ['out_beg_match'] + ['out_end_match'] + ['out_year_overlap']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# adding the 'match_strength' column\n",
    "df['out_content_match_strength'] = 0\n",
    "output_fields += ['out_content_match_strength']\n",
    "\n",
    "if ('input_x_coord' in input_fields):\n",
    "    if coord_mode == \"strict\":\n",
    "        df['out_content_match_strength'] += df['out_x_coord_match'].astype(int)\n",
    "    else: \n",
    "        df['out_content_match_strength'] += df['fuzzy_out_x_coord_match'].astype(int)\n",
    "\n",
    "if ('input_y_coord' in input_fields):\n",
    "    if coord_mode == \"strict\":\n",
    "        df['out_content_match_strength'] += df['out_y_coord_match'].astype(int)\n",
    "    else: \n",
    "        df['out_content_match_strength'] += df['fuzzy_out_y_coord_match'].astype(int)\n",
    "    \n",
    "if ('input_beg_year' in input_fields):\n",
    "    df['out_content_match_strength'] += df['out_beg_match'].astype(int) \n",
    "    \n",
    "if ('input_end_year' in input_fields):\n",
    "    df['out_content_match_strength'] += df['out_end_match'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# sorting columns\n",
    "#print(output_fields)\n",
    "ordered_fields = tgaz_fields + input_fields + ['_merge'] + output_fields\n",
    "#print(ordered_fields)\n",
    "fuzzy_ordered_fields = ['fuzzy_nm'] + ordered_fields\n",
    "\n",
    "if name_mode == 'strict':\n",
    "    df = df[ordered_fields]\n",
    "else:\n",
    "    df = df[fuzzy_ordered_fields]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# replacing 'nan' with '' for improved legibility\n",
    "df = df.replace('nan', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data check is complete.  Please input the path (with file extension) to which you want to write the results:\n",
      "\n",
      "160909_text_error3.csv\n",
      "File created at 160909_text_error3.csv.  Now exiting.\n"
     ]
    }
   ],
   "source": [
    "# outputting results\n",
    "print('\\nData check is complete.  Please input the path (with file extension) to which you want to write the results:\\n')\n",
    "output_path = input()\n",
    "\n",
    "while not output_path.endswith('.csv'):\n",
    "        print(\"Filename does not end in .csv -- please try again or use Ctrl-C to exit:\")\n",
    "        output_path = input()\n",
    "\n",
    "df.to_csv(output_path)\n",
    "\n",
    "print('File created at %s.  Now exiting.' % output_path)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
