{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#! /usr/bin/python3\n",
    "\n",
    "# Script for comparing an input .csv file with an existing .csv file (e.g. the current CHGIS).\n",
    "# Indicates 1) matches on name and 2) strength of match on content\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import Series, DataFrame\n",
    "import os.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def name_checker(name):\n",
    "    '''\n",
    "       Confirms that pathname is a valid file \n",
    "    '''\n",
    "    while not (os.path.isfile(name)):\n",
    "        print(\"Not a valid filename.  Please try again.\")\n",
    "        name = input()\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def csv_picker():\n",
    "    '''\n",
    "        Simple function that takes the filenames / paths of the new .csv to check and the old .csv (i.e. a CHGIS version) against which to check it.\n",
    "        Returns a list from which the DataFrames can then be constructed.\n",
    "    '''\n",
    "    print(\"Please type in the path of the file (with extension) you wish to check against the CHGIS:\")\n",
    "    new_csv = input()\n",
    "    new_csv = name_checker(new_csv)\n",
    "    #while !os.path.isfile(new_csv):\n",
    "    #    print(\"Not a valid filename.  Please try again:\")\n",
    "    #    new_csv = input()\n",
    "    print(\"Please type in the path of the file (with extension) containing the version of the CHGIS you wish to check against:\")\n",
    "    old_csv = input()\n",
    "    old_csv = name_checker(old_csv)\n",
    "    return [new_csv, old_csv]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# def field_checker(new_csv, old_csv):\n",
    "#    '''\n",
    "#        Contains the logic for checking fields of the new_csv against those of the old_csv \n",
    "#        Presumes the existence of the following cols:       \n",
    "#    '''\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        藍氏城\n",
      "1         高德\n",
      "2         薊縣\n",
      "3         良鄉\n",
      "4         廣陽\n",
      "5         狐奴\n",
      "6         安樂\n",
      "7         軍都\n",
      "8         昌平\n",
      "9         平谷\n",
      "10        傂奚\n",
      "11        獷平\n",
      "12        漁陽\n",
      "13        居庸\n",
      "14        雍奴\n",
      "15        泉州\n",
      "16        無終\n",
      "17        真定\n",
      "18        井陘\n",
      "19        新市\n",
      "20       南行唐\n",
      "21        靈壽\n",
      "22        高邑\n",
      "23        房子\n",
      "24       南深澤\n",
      "25        毋極\n",
      "26        元氏\n",
      "27        欒城\n",
      "28        平棘\n",
      "29        阜城\n",
      "        ... \n",
      "77739    NaN\n",
      "77740    NaN\n",
      "77741    NaN\n",
      "77742    NaN\n",
      "77743    NaN\n",
      "77744    NaN\n",
      "77745    NaN\n",
      "77746    NaN\n",
      "77747    NaN\n",
      "77748    NaN\n",
      "77749    NaN\n",
      "77750    NaN\n",
      "77751    NaN\n",
      "77752    NaN\n",
      "77753    NaN\n",
      "77754    NaN\n",
      "77755    NaN\n",
      "77756    NaN\n",
      "77757    NaN\n",
      "77758    NaN\n",
      "77759    NaN\n",
      "77760    NaN\n",
      "77761    NaN\n",
      "77762    NaN\n",
      "77763    NaN\n",
      "77764    NaN\n",
      "77765    NaN\n",
      "77766    NaN\n",
      "77767    NaN\n",
      "77768    NaN\n",
      "Name: 县名, dtype: object\n"
     ]
    }
   ],
   "source": [
    "### start of test to see if Donghan_2014-10-02_copy.csv as new, chgis v5 as old works\n",
    "\n",
    "# importing .csv files\n",
    "dong_han = pd.read_csv('../input/sample_data/Donghan_2014-10-02_copy.csv', low_memory=False)\n",
    "v5 = pd.read_csv('../input/v5_augment_2016-08-09.csv', low_memory=False)\n",
    "\n",
    "# tagging source files\n",
    "dong_han['data_source'] = 'dong_han'\n",
    "v5['data_source'] = 'v5'\n",
    "\n",
    "# appending 县 to '县名' column, placing into 'nm_simp' col to prepare data for import into v5\n",
    "dong_han['nm_simp'] = dong_han['县名'] + '县'\n",
    "\n",
    "# renaming cols of dong_han to match v5\n",
    "dong_han = dong_han.rename(columns={\n",
    "        '經度':'x_coord',\n",
    "        '緯度':'y_coord',\n",
    "        '屬':'prnt_simp',\n",
    "        'BEG':'beg',\n",
    "        'END':'end'        \n",
    "    })\n",
    "\n",
    "# concatenating into a single DF\n",
    "df = pd.concat([dong_han, v5])\n",
    "print(df['县名'])\n",
    "#df.to_csv('../output/160829_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/sf/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "# checking for duplicated names\n",
    "mask_duplicates = df.duplicated(subset='nm_simp', keep=False)\n",
    "mask_uniques = ~mask_duplicates\n",
    "duplicates = df[mask_duplicates]\n",
    "duplicates['nm_simp_match'] = True\n",
    "uniques = df[mask_uniques]\n",
    "uniques['nm_simp_match'] = False\n",
    "df_two = pd.concat([duplicates, uniques])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function for comparing content fields\n",
    "def field_matcher(frame, comp_field, indicator_field):\n",
    "    ''' Simple function that, within the given pandas DataFrame (`frame`) creates a new \n",
    "        field (`indicator_field`) that displays Boolean value indicating whether the given \n",
    "        field (`comp_field`)'s value in that row matches at least one other row's value for it. \n",
    "    \n",
    "        Uses a masking procedure -- identify duplicates and uniques, create new DataFrames using \n",
    "        the resulting two Boolean series as masks, and then concatenate them back together.\n",
    "    \n",
    "        PRESUMES that `frame` is a concatenation of two other DataFrames, each of which initially\n",
    "        lack any duplicate rows -- that is, if you run this function on either contributing DataFrame,\n",
    "        with the key field (e.g. `sys_id`) as `comp_field`, it will find no matches whatsoever\n",
    "    '''\n",
    "    \n",
    "    mask_duplicates = frame.duplicated(subset=[comp_field], keep=False)\n",
    "    mask_uniques = ~mask_duplicates\n",
    "    duplicates = frame[mask_duplicates]\n",
    "    duplicates[indicator_field] = True\n",
    "    uniques = frame[mask_uniques]\n",
    "    uniques[indicator_field] = False\n",
    "    return pd.concat([duplicates, uniques])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/sf/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "# checking content matches\n",
    "\n",
    "# trying to workaround failure to recognize numerical matches\n",
    "df_two['x_coord'] = df_two['x_coord'].astype(str)\n",
    "df_two['y_coord'] = df_two['y_coord'].astype(str)\n",
    "df_two['beg'] = df_two['beg'].astype(str)\n",
    "df_two['end'] = df_two['end'].astype(str)\n",
    "\n",
    "# creating flag fields for content matches\n",
    "df_three = field_matcher(df_two, 'x_coord', 'x_coord_match')\n",
    "df_four = field_matcher(df_three,'y_coord', 'y_coord_match')\n",
    "df_five = field_matcher(df_four,'beg', 'beg_match')\n",
    "df_six = field_matcher(df_five,'end', 'end_match')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['beg', 'data_source', 'end', 'nm_py', 'nm_simp', 'nm_trad', 'obj_type',\n",
      "       'pres_loc', 'prnt_id', 'prnt_py', 'prnt_simp', 'prnt_sysid', 'seq',\n",
      "       'src', 'sys_id', 'type_ch', 'type_py', 'x_coord', 'y_coord', '县名',\n",
      "       '地名分類', '年代', '朝代', '舊規範碼', '行政區', '規範碼', 'nm_simp_match',\n",
      "       'x_coord_match', 'y_coord_match', 'beg_match', 'end_match',\n",
      "       'content_match_strength'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "### adding the 'match_strength' column\n",
    "df_six['content_match_strength'] = df_six['x_coord_match'].astype(int) + df_six['y_coord_match'].astype(int) + df_six['beg_match'].astype(int) + df_six['end_match'].astype(int)\n",
    "print(df_six.columns)\n",
    "# Perhaps refactor using https://stackoverflow.com/questions/25748683/python-pandas-sum-dataframe-rows-for-given-columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# rearrange the columns\n",
    "df_six = df_six[['sys_id', 'x_coord', 'y_coord', 'beg', 'end', '县名', 'nm_simp_match', 'x_coord_match', 'y_coord_match', 'beg_match', 'end_match', 'content_match_strength']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# write to file\n",
    "df_six.to_csv('../output/Dong_Han_added_to_v5_rev_160901.csv')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
