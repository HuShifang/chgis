{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#! /usr/bin/python3\n",
    "\n",
    "# Script for comparing an input .csv file with an existing .csv file (e.g. the current CHGIS).\n",
    "# Indicates 1) matches on name and 2) strength of match on content\n",
    "# Requires the library 'pandas' to be installed, which is included in Anaconda's free Python distribution\n",
    "\n",
    "# by Stephen Ford (stephen.p.ford@gmail.com)\n",
    "\n",
    "import pandas as pd\n",
    "import os.path\n",
    "\n",
    "# suppressing SettingWithCopyWarning\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# function for selecting .csv files for manipulation\n",
    "\n",
    "def csv_picker():\n",
    "    ''' Function for checking whether user input path 1) is that of a valid file, and 2) is of a file ending with '.csv'\n",
    "        Prompts for re-entry if entry is invalid.\n",
    "        Returns a pandas DataFrame constructed from the valid .csv file\n",
    "    '''\n",
    "    name = input()\n",
    "\n",
    "    # checking that the path is a valid filename, and prompting for re-entry if not\n",
    "    while not (os.path.isfile(name)):\n",
    "        print(\"Not a valid filename.  Please try again:\")\n",
    "        name = input()\n",
    "        \n",
    "    # checking that the valid filename ends in .csv, prompting for re-entry if not\n",
    "    while not name.endswith('.csv'):\n",
    "        print(\"Filename does not end in .csv -- please try again:\")\n",
    "        name = input()\n",
    "\n",
    "    print(\"\\nThank you -- filename %s is valid.\\n\" % name)       \n",
    "    return pd.read_csv(name, low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function for mapping the input .csv's fields to the desired, standardized output fields\n",
    "def field_mapper(std_field, frame, fields):\n",
    "    ''' Function that will prompt user to manually map fields of the input .csv to standardized output fields.\n",
    "        Name changes will be made in-place (i.e. in the DataFrame -- the .csv will be untouched).\n",
    "        If user fails to enter anything for the given mapping, that field will dropped from the final output file.        \n",
    "    '''\n",
    "    \n",
    "    print(\"\\nPlease enter the field that will be labeled '%s' in the output .csv:\" % std_field)\n",
    "    orig_field = input()\n",
    "    \n",
    "    # prompts for re-entering the input field if 1) it is not one of the column names and 2) it isn't an empty string\n",
    "    while (not orig_field in list(frame.columns)) and (orig_field):\n",
    "        print(\"\\nNot a valid column name.  Please try again:\")\n",
    "        orig_field = input()\n",
    "        \n",
    "    # simply exit if the user pressed enter, bypassing the mapping, or perform the mapping if a valid field name has been entered\n",
    "    if orig_field:\n",
    "        frame.rename(columns={orig_field:std_field}, inplace=True)\n",
    "        fields += [std_field]\n",
    "    return fields\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def name_checker(name_fields, fields, prefix, frame):\n",
    "    ''' Function will confirm that at least one name field has been entered, and prompt user to remap the three\n",
    "        name fields until at least one is a valid entry. Updates the DataFrame in-place and returns the updated field list.\n",
    "    '''\n",
    "    \n",
    "    while (((name_fields[0] in fields) or (name_fields[1] in fields) or (name_fields[2] in fields)) == False):\n",
    "        print(\"At least one name field needs to be specified. Please try again.\")\n",
    "        # counter ensures that name fields are inserted at correct place in sequence\n",
    "        counter = 1\n",
    "        for name_field in name_fields:\n",
    "            print(\"Please enter the field that will be labeled '%s' in the output .csv:\" % name_field)\n",
    "            orig_field = input()\n",
    "            if orig_field:\n",
    "                if (orig_field in list(frame.columns)):\n",
    "                    frame.rename(columns={orig_field:name_field}, inplace=True)\n",
    "                    fields.insert(counter, name_field)\n",
    "                    counter+=1\n",
    "                else: \n",
    "                    print(\"Input not accepted -- field not found in data.\")\n",
    "    return fields\n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# offering user choice of strict or fuzzy name-matching\n",
    "\n",
    "def merge_chooser(target_field, incoming_field):\n",
    "    ''' Function called only if the user selects to merge on traditional characters 繁體字 or simplified characters 简体字\n",
    "        Lets user choose whether to do a strict or fuzzy merge.\n",
    "        In a fuzzy merge, only the first two characters of the Chinese names will be checked against one another.\n",
    "    '''\n",
    "    print(\n",
    "    '''\n",
    "Please indicate, by entering a numerical digit 1-2, whether you wish to do a strict or fuzzy match of names:\n",
    "    1. Strict matching (e.g. '張掖' matches '張掖', but '張掖' does not match '張掖居延屬國')\n",
    "    2. Fuzzy matching (e.g. '張掖' matches '張掖', and '張掖' also matches '張掖居延屬國')\n",
    "    ''')\n",
    "\n",
    "    accepted = False\n",
    "    choice = input()\n",
    "\n",
    "    while accepted == False:\n",
    "        if choice == '1':\n",
    "            print('Proceeding with strict matching of names.')\n",
    "            accepted = True\n",
    "            mode = 'strict'\n",
    "            df = target.merge(incoming, how='outer', left_on=target_field, right_on=incoming_field, indicator=True)\n",
    "            return df, mode\n",
    "        elif choice == '2':\n",
    "            print('Proceeding with fuzzy matching of names.')\n",
    "            accepted = True\n",
    "            mode = 'fuzzy'\n",
    "            target['fuzzy_nm'] = target[target_field].map(lambda x: x[:2])\n",
    "            incoming['fuzzy_nm'] = incoming[incoming_field].map(lambda x: x[:2])\n",
    "            df = target.merge(incoming, how='outer', on='fuzzy_nm', indicator=True)\n",
    "            return df, mode\n",
    "        else:\n",
    "            print(\"\\nNot a valid response.  Please try again:\\n\")\n",
    "            choice = input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def coordinate_matcher(coords, frame, fields):\n",
    "    ''' Function that performs a strict or fuzzy matching of spatial coordinates.  Returns a string indicating the type of match performed.\n",
    "        The matches' results are added to the DataFrame within the function.\n",
    "    '''\n",
    "    \n",
    "    print(\n",
    "        '''\n",
    "    Please indicate, by entering a numerical digit 1-2, whether you wish to do a strict or fuzzy match of spatial coordinates:\n",
    "        1. Strict matching (requires exact match, e.g. '119.64656' does NOT match '119.646560', '119.64657', or '119.325')\n",
    "        2. Fuzzy matching (requires only that rounded numbers match -- you specify the number of decimal places)\n",
    "        ''')\n",
    "\n",
    "    accepted = False\n",
    "    choice = input()\n",
    "\n",
    "    while accepted == False:\n",
    "        if choice == '1':\n",
    "            print('Proceeding with strict matching of spatial coordinates.')\n",
    "            accepted = True\n",
    "            for coord in coords:\n",
    "                frame['out_%s_coord_match' % coord] = frame['input_%s_coord' % coord] == frame['tgaz_%s_coord' % coord]\n",
    "                fields += ['out_%s_coord_match' % coord]\n",
    "            return \"strict\"\n",
    "        elif choice == '2':\n",
    "            print(\"Proceeding with fuzzy matching of spatial coordinates.\")\n",
    "            accepted = True\n",
    "            print('''Please enter a number indicating the number of decimal places to which to round the decimal coordinate value.\n",
    "                      For example, if you enter 0, 117.91 and 118.08 will round to 118 and match; if you enter 1, 117.91 will round to 117.9 and 118.08 will round to 118.1, and they won't match.\n",
    "                      Be advised that coordinates rarely have more than 7 decimal places of precision.\n",
    "                  ''')\n",
    "            decimal_place = input()\n",
    "            try: \n",
    "                for coord in coords:\n",
    "                    frame['fuzzy_out_%s_coord_match' % coord] = frame['input_%s_coord' % coord].map(lambda x: round(x, int(decimal_place))) == frame['tgaz_%s_coord' % coord].map(lambda x: round(x, int(decimal_place)))\n",
    "                    fields += ['fuzzy_out_%s_coord_match' % coord]\n",
    "                return \"fuzzy\"\n",
    "                                                                                                \n",
    "            except:\n",
    "                print(\"Not a valid response. Defaulting to 0 (integer-rounding).\")\n",
    "                for coord in coords:\n",
    "                    frame['fuzzy_out_%s_coord_match' % coord] = frame['input_%s_coord' % coord].map(lambda x: round(x, 0)) == frame['tgaz_%s_coord' % coord].map(lambda x: round(x, 0))\n",
    "                    fields += ['fuzzy_out_%s_coord_match' % coord]\n",
    "                return \"fuzzy\" \n",
    "        else:\n",
    "            print(\"\\nNot a valid response.  Please try again:\\n\")\n",
    "            choice = input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please type the path of the incoming .csv file (with extension):\n",
      "/home/sf/chgis/input/sample_data/Donghan_2014-10-02_copy.csv\n",
      "\n",
      "Thank you -- filename /home/sf/chgis/input/sample_data/Donghan_2014-10-02_copy.csv is valid.\n",
      "\n",
      "Please type the path of the target .csv file (with extension):\n",
      "/home/sf/chgis/input/v5_augment_2016-08-09.csv\n",
      "\n",
      "Thank you -- filename /home/sf/chgis/input/v5_augment_2016-08-09.csv is valid.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# soliciting files for comparison; presumption is that second file entered will be the CHGIS v5 in .csv format\n",
    "print(\"Please type the path of the incoming .csv file (with extension):\")\n",
    "incoming = csv_picker()\n",
    "# /home/sf/chgis/input/sample_data/Donghan_2014-10-02_copy.csv\n",
    "# /home/sf/chgis/input/sample_data/lexdata.txt.data.csv\n",
    "\n",
    "print(\"Please type the path of the target .csv file (with extension):\")\n",
    "target = csv_picker()\n",
    "# /home/sf/chgis/input/v5_augment_2016-08-09.csv\n",
    "# /home/sf/chgis/input/V6_input_draft_20160811.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Populating the initial columns of the two spreadheets, and initializing the lists for the final output (unused fields will be dropped)\n",
    "\n",
    "# initializing list of incoming_fields \n",
    "incoming_fields = []\n",
    "\n",
    "# declaring the list of output .csv field names that will derive from the new data\n",
    "# i.e., all those fields whose names will be 'input_*' in the final .csv\n",
    "final_incoming_fields = [   \n",
    "    'input_id',\n",
    "    'input_nm_py',\n",
    "    'input_nm_simp',\n",
    "    'input_nm_trad',\n",
    "    'input_type',\n",
    "    'input_year_beg',\n",
    "    'input_year_end',\n",
    "    'input_dynasty',\n",
    "    'input_other_id',\n",
    "    'input_prnt',\n",
    "    'input_obj_type',\n",
    "    'input_x_coord',\n",
    "    'input_y_coord'\n",
    "]\n",
    "\n",
    "\n",
    "# initializing list of actual target fields\n",
    "target_fields = []\n",
    "\n",
    "# initializing list of default CHGIS fields (taken from v5_augment_2016-08-09.csv)\n",
    "default_target_fields = [\n",
    "    'seq', \n",
    "    'sys_id', \n",
    "    'src', \n",
    "    'nm_py', \n",
    "    'nm_simp', \n",
    "    'nm_trad', \n",
    "    'x_coord', \n",
    "    'y_coord', \n",
    "    'pres_loc', \n",
    "    'type_py', \n",
    "    'type_ch', \n",
    "    'beg', \n",
    "    'end', \n",
    "    'obj_type',\n",
    "    'prnt_id', \n",
    "    'prnt_sysid', \n",
    "    'prnt_simp', \n",
    "    'prnt_py'\n",
    "]\n",
    "\n",
    "# initializing list of tgaz fields (i.e. the standardized output-form of the CHGIS fields)\n",
    "final_target_fields = [\n",
    "    'tgaz_sys_id',\n",
    "    'tgaz_nm_py',\n",
    "    'tgaz_nm_simp',\n",
    "    'tgaz_nm_trad',\n",
    "    'tgaz_beg',\n",
    "    'tgaz_end',\n",
    "    'tgaz_data_source',\n",
    "    'tgaz_obj_type',\n",
    "    'tgaz_pres_loc',\n",
    "    'tgaz_prnt_id',\n",
    "    'tgaz_prnt_py',\n",
    "    'tgaz_prnt_simp',\n",
    "    'tgaz_prnt_sysid',\n",
    "    'tgaz_type_ch',\n",
    "    'tgaz_type_py',\n",
    "    'tgaz_x_coord',\n",
    "    'tgaz_y_coord'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please indicate by entering '1' or '2' whether you wish to use a default mapping of CHGIS fields, or wish to manually map fields.\n",
      "    \n",
      "1. Use the default mapping -- presumes the input CHGIS file has the following columns:\n",
      "\n",
      "  ['seq', 'sys_id', 'src', 'nm_py', 'nm_simp', 'nm_trad', 'x_coord', 'y_coord', 'pres_loc', 'type_py', 'type_ch', 'beg', 'end', 'obj_type', 'prnt_id', 'prnt_sysid', 'prnt_simp', 'prnt_py']\n",
      "\n",
      "2. Use a manual mapping -- you will be prompted to indicate which column from the file should map to which output column.\n",
      "\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "### presenting user with choice of a default mapping of CHGIS fields (based on v5_augment_2016-08-09.csv) or of manually entering their own mapping\n",
    "\n",
    "print('''Please indicate by entering '1' or '2' whether you wish to use a default mapping of CHGIS fields, or wish to manually map fields.\n",
    "    \n",
    "1. Use the default mapping -- presumes the input CHGIS file has the following columns:\n",
    "\n",
    "  %s\n",
    "\n",
    "2. Use a manual mapping -- you will be prompted to indicate which column from the file should map to which output column.\n",
    "''' % str(default_target_fields))\n",
    "\n",
    "accepted = False\n",
    "mapping = input()\n",
    "\n",
    "while accepted == False:\n",
    "    # checks them against one another using comparison of sets (which are collections of unordered, unique items)\n",
    "    if (mapping == '1'):\n",
    "        if (set(list(target.columns)) == set(default_target_fields)):\n",
    "            # manually renaming one exception to the following pattern\n",
    "            target.rename(columns={'src':'data_source'}, inplace=True)\n",
    "\n",
    "            # manually dropping the seq field\n",
    "            del target['seq']\n",
    "\n",
    "            # renaming the CHGIS fields in-place to conform to output specifications\n",
    "            target.columns = ['tgaz_%s' % x for x in target.columns]\n",
    "            # FOR TESTING ONLY\n",
    "            if (set(list(target.columns)) != set(final_target_fields)):\n",
    "                print(\"POSSIBLE ERROR\")\n",
    "                print(\"chgis.columns is %s\" % str(list(chgis.columns)))\n",
    "                print(\"final_chgis_fields is %s\" % str(final_chgis_fields))\n",
    "                print(\"set difference is %s\" % str(set(list(chgis.columns)).difference(set(final_chgis_fields))))\n",
    "            target = target[final_target_fields]\n",
    "            accepted = True\n",
    "        else: \n",
    "            print(\"The columns in the selected CHGIS spreadsheet do not precisely match expectations. \\n\\n Proceeding with manual mapping.\")\n",
    "            for field in final_target_fields:\n",
    "                target_fields = field_mapper(field, target, target_fields)  \n",
    "            target_fields = name_checker(['tgaz_nm_py', 'tgaz_nm_simp', 'tgaz_nm_trad'], target_fields, \"tgaz\", target)\n",
    "            target = target[target_fields]\n",
    "            accepted = True\n",
    "    elif (mapping == '2'):\n",
    "        print(\"Now, please specify fields from the CHGIS (match-receiving) data that will be included in the final spreadsheet.\\n\")\n",
    "        for field in final_target_fields:\n",
    "            target_fields = field_mapper(field, target, target_fields)  \n",
    "        target_fields = name_checker(['tgaz_nm_py', 'tgaz_nm_simp', 'tgaz_nm_trad'], target_fields, \"tgaz\", target)\n",
    "        target = target[target_fields]\n",
    "        accepted = True\n",
    "    else:\n",
    "        print(\"\\nNot a valid response.  Please try again:\\n\")\n",
    "        mapping = input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now we will specify fields from the incoming (match-making) data that will be included in the final spreadsheet.\n",
      "\n",
      "\n",
      "Please enter the field that will be labeled 'input_id' in the output .csv:\n",
      "規範碼\n",
      "\n",
      "Please enter the field that will be labeled 'input_nm_py' in the output .csv:\n",
      "县名\n",
      "\n",
      "Please enter the field that will be labeled 'input_nm_simp' in the output .csv:\n",
      "\n",
      "\n",
      "Please enter the field that will be labeled 'input_nm_trad' in the output .csv:\n",
      "\n",
      "\n",
      "Please enter the field that will be labeled 'input_type' in the output .csv:\n",
      "\n",
      "\n",
      "Please enter the field that will be labeled 'input_year_beg' in the output .csv:\n",
      "BEG\n",
      "\n",
      "Please enter the field that will be labeled 'input_year_end' in the output .csv:\n",
      "END\n",
      "\n",
      "Please enter the field that will be labeled 'input_dynasty' in the output .csv:\n",
      "\n",
      "\n",
      "Please enter the field that will be labeled 'input_other_id' in the output .csv:\n",
      "\n",
      "\n",
      "Please enter the field that will be labeled 'input_prnt' in the output .csv:\n",
      "\n",
      "\n",
      "Please enter the field that will be labeled 'input_obj_type' in the output .csv:\n",
      "\n",
      "\n",
      "Please enter the field that will be labeled 'input_x_coord' in the output .csv:\n",
      "經度\n",
      "\n",
      "Please enter the field that will be labeled 'input_y_coord' in the output .csv:\n",
      "緯度\n"
     ]
    }
   ],
   "source": [
    "# renaming fields in the incoming DataFrame to conform to specifications\n",
    "\n",
    "print(\"Now we will specify fields from the incoming (match-making) data that will be included in the final spreadsheet.\\n\")\n",
    "for field in final_incoming_fields:\n",
    "    incoming_fields = field_mapper(field, incoming, incoming_fields)    \n",
    "\n",
    "incoming_fields = name_checker(['input_nm_py', 'input_nm_simp', 'input_nm_trad'], incoming_fields, \"input\", incoming)\n",
    "incoming = incoming[incoming_fields]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# dropping fields from the incoming DataFrame that weren't mapped\n",
    "#for field in incoming.columns:\n",
    "#    if incoming[field].empty:\n",
    "#        incoming.drop(field, inplace=True)\n",
    "#        input_fields.remove(field)\n",
    "        \n",
    "#print(\"input_fields are: %s\" % str(input_fields))\n",
    "#print(\"incoming cols are: %s\" % str(incoming.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# manually renaming one exception to the following pattern\n",
    "#chgis.rename(columns={'src':'data_source'}, inplace=True)\n",
    "\n",
    "# renaming the CHGIS fields in-place to conform to output specifications\n",
    "#chgis.columns = ['tgaz_%s' % x for x in chgis.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Thank you. Now, please indicate, by entering a numerical digit 1-3, which of the following names you wish to make the primary key for comparing data:\n",
      "    1. Name in complex/traditional Chinese characters 繁体字\n",
      "    2. Name in simplified Chinese characters 简体字\n",
      "    3. Name in pinyin 拼音\n",
      "    \n",
      "3\n",
      "\n",
      "Using name in pinyin 拼音 as primary matching key.\n",
      "Fuzzy matching is not currently supported for pinyin names.  Proceeding with strict matching.\n"
     ]
    }
   ],
   "source": [
    "# soliciting user choice regarding which name field to take as primary\n",
    "print(\n",
    "    '''\n",
    "Thank you. Now, please indicate, by entering a numerical digit 1-3, which of the following names you wish to make the primary key for comparing data:\n",
    "    1. Name in complex/traditional Chinese characters 繁体字\n",
    "    2. Name in simplified Chinese characters 简体字\n",
    "    3. Name in pinyin 拼音\n",
    "    '''\n",
    ")\n",
    "\n",
    "accepted = False\n",
    "choice = input()\n",
    "\n",
    "while accepted == False:\n",
    "    if ((choice == '1') and ('input_nm_trad' in incoming_fields)):\n",
    "        print(\"\\nUsing name in complex/traditional Chinese characters 繁体字 as primary matching key.\")\n",
    "        accepted = True\n",
    "        incoming_name_match_field = 'input_nm_trad'\n",
    "        target_name_match_field = 'tgaz_nm_trad'\n",
    "        df, name_mode = merge_chooser(target_name_match_field, incoming_name_match_field)\n",
    "    elif ((choice == '2') and ('input_nm_simp' in incoming_fields)):\n",
    "        print(\"\\nUsing name in simplified Chinese characters 简体字 as primary matching key.\")\n",
    "        accepted = True\n",
    "        incoming_name_match_field = 'input_nm_simp'\n",
    "        target_name_match_field = 'tgaz_nm_simp'\n",
    "        df, name_mode = merge_chooser(target_name_match_field, incoming_name_match_field)\n",
    "    elif ((choice == '3') and ('input_nm_py' in incoming_fields)):\n",
    "        print(\"\\nUsing name in pinyin 拼音 as primary matching key.\")\n",
    "        accepted = True\n",
    "        incoming_name_match_field = 'input_nm_py'\n",
    "        target_name_match_field = 'tgaz_nm_py'\n",
    "        name_mode = 'strict'\n",
    "        print('Fuzzy matching is not currently supported for pinyin names.  Proceeding with strict matching.')\n",
    "        df = target.merge(incoming, how='outer', left_on=target_name_match_field, right_on=incoming_name_match_field, indicator=True)\n",
    "        \n",
    "    else:\n",
    "        print(\"\\nNot a valid response.  Please try again, entering a choice corresponding to a valid field:\\n\")\n",
    "        choice = input()\n",
    "        \n",
    "output_fields = []            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# removing rows that are only present in the CHGIS file\n",
    "df = df[df['_merge'] != 'left_only']\n",
    "\n",
    "# renaming merge indicators for legibility\n",
    "df = df.replace(to_replace='both', value='found')\n",
    "df = df.replace(to_replace='right_only', value='not_found')\n",
    "df.rename(columns={'_merge':'match'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in the for loop\n",
      "converting input_x_coord\n",
      "in the for loop\n",
      "converting input_y_coord\n",
      "in the for loop\n",
      "in the for loop\n",
      "\n",
      "    Please indicate, by entering a numerical digit 1-2, whether you wish to do a strict or fuzzy match of spatial coordinates:\n",
      "        1. Strict matching (requires exact match, e.g. '119.64656' does NOT match '119.646560', '119.64657', or '119.325')\n",
      "        2. Fuzzy matching (requires only that rounded numbers match -- you specify the number of decimal places)\n",
      "        \n",
      "2\n",
      "Proceeding with fuzzy matching of spatial coordinates.\n",
      "Please enter a number indicating the number of decimal places to which to round the decimal coordinate value.\n",
      "                      For example, if you enter 0, 117.91 and 118.08 will round to 118 and match; if you enter 1, 117.91 will round to 117.9 and 118.08 will round to 118.1, and they won't match.\n",
      "                      Be advised that coordinates rarely have more than 7 decimal places of precision.\n",
      "                  \n",
      "2\n"
     ]
    }
   ],
   "source": [
    "#### Abandoning comprehensive for-loop for sake of year matching; manually stringifying coords instead\n",
    "\n",
    "# converting all fields to strings for ease of comparison\n",
    "#for field in list(df.columns):\n",
    "#    df[field] = df[field].astype(str)\n",
    "spatial_coords = ['input_x_coord', 'input_y_coord', 'tgaz_x_coord', 'tgaz_y_coord']\n",
    "\n",
    "# converting the given field's values to a numeric, or NaN, for possible rounding later\n",
    "try: \n",
    "    for field in spatial_coords:\n",
    "        print(\"in the for loop\")\n",
    "        if (field in incoming_fields) or (field in target_fields):\n",
    "            print(\"converting %s\" % field)\n",
    "            df[field] = pd.to_numeric(df[field], errors='coerce')\n",
    "    if ('input_x_coord' in incoming_fields) and ('input_y_coord' in incoming_fields):\n",
    "        coord_mode = coordinate_matcher(['x', 'y'], df, output_fields)\n",
    "    elif ('input_x_coord' in incoming_fields) and not ('input_y_coord' in incoming_fields):\n",
    "        coord_mode = coordinate_matcher(['x'], df, output_fields)\n",
    "    elif not ('input_x_coord' in incoming_fields) and ('input_y_coord' in incoming_fields):\n",
    "        coord_mode = coordinate_matcher(['y'], df, output_fields)\n",
    "    else:\n",
    "        print(\"\\nNo spatial coordinate fields available for matching.\")\n",
    "except KeyError:\n",
    "    print(\"Spatial coordinates not properly entered. Skipping coordinate matching.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "############## NEW ################\n",
    "#if (df['input_year_beg'].empty() | df['input_year_end'].empty()):\n",
    "#    if (df['input_year_beg'].empty()):\n",
    "#        df.drop(['input_year_beg'])\n",
    "#        input_fields.remove('input_year_beg')\n",
    "#        beg_year_matching = False\n",
    "#    if (df['input_year_end'].empty()):\n",
    "#        df.drop(['input_year_end'])\n",
    "#        input_fields.remove('input_year_end')\n",
    "#        end_year_matching = False\n",
    "\n",
    "if (not 'input_year_beg' in incoming_fields) or (not 'input_year_end' in incoming_fields):\n",
    "    print(\"Incoming data lacks a beginning and/or ending year field; no date comparisons will be made.\")\n",
    "else:\n",
    "    # beg_year_matching, end_year_matching = True, True\n",
    "    \n",
    "    year_fields = ['input_year_beg', 'input_year_end', 'tgaz_beg', 'tgaz_end']\n",
    "    \n",
    "    #for field in year_fields:\n",
    "    #    print(df[field].dtype)\n",
    "           \n",
    "    # overlap field initialization\n",
    "    df['out_year_overlap'] = ''\n",
    "\n",
    "           \n",
    "    # converting to type float64 (invalid years become 'NaN', and pandas.isnull(<Series_(column)>) returns True for those values\n",
    "    for year_field in year_fields:\n",
    "        df[year_field] = pd.to_numeric(df[year_field], errors='coerce')\n",
    "    \n",
    "    # in-row match testing\n",
    "    df['out_beg_match'] = df['input_year_beg'] == df['tgaz_beg']\n",
    "    df['out_end_match'] = df['input_year_end'] == df['tgaz_end']\n",
    "    \n",
    "    # testing for timespan relationships\n",
    "    df['out_year_overlap'][((df['input_year_beg'] == (df['tgaz_end'] + 1)) | (df['input_year_end'] == (df['tgaz_beg'] - 1)))] = 'adjacent'\n",
    "    df['out_year_overlap'][(df['input_year_beg'] <= df['tgaz_beg']) & (df['input_year_end'] >= df['tgaz_beg']) & (df['input_year_end'] < df['tgaz_end'])] = 'partial_incl_start_of_target'\n",
    "    df['out_year_overlap'][(df['input_year_beg'] > df['tgaz_beg']) & (df['input_year_beg'] <= df['tgaz_end']) & (df['input_year_end'] >= df['tgaz_end'])] = 'partial_incl_end_of_target'\n",
    "    df['out_year_overlap'][((df['input_year_beg'] >= df['tgaz_beg']) & (df['input_year_end'] < df['tgaz_end'])) | ((df['input_year_beg'] > df['tgaz_beg']) & (df['input_year_end'] <= df['tgaz_end']))] = 'incoming_nested_in_target'\n",
    "    df['out_year_overlap'][((df['input_year_beg'] <= df['tgaz_beg']) & (df['input_year_end'] > df['tgaz_end']) | (df['input_year_beg'] < df['tgaz_beg']) & (df['input_year_end'] >= df['tgaz_end']))] = 'target_nested_in_incoming'\n",
    "    df['out_year_overlap'][(df['input_year_beg'] == df['tgaz_beg']) & (df['input_year_end'] == df['tgaz_end'])] = 'perfect_match'\n",
    "    df['out_year_overlap'][(df['input_year_beg'] == 0) | (df['input_year_end'] == 0) | (df['tgaz_beg'] == 0) | (df['tgaz_end'] == 0)] = 'CAUTION__ZEROES'\n",
    "    df['out_year_overlap'][(df['input_year_beg'] > df['input_year_end']) | (df['tgaz_beg'] > df['tgaz_end'])] = 'ERROR__END_BEFORE_BEG'\n",
    "    \n",
    "    # designating items with non-numeric text values in at least one year field (which therefore break the overlap checker)\n",
    "    df['out_year_overlap'][(df['match'] == 'found') & (pd.isnull(df['input_year_beg']) | pd.isnull(df['input_year_end']) | pd.isnull(df['tgaz_beg']) | pd.isnull(df['tgaz_end']))] = 'ERROR__NON_NUMERIC_YEAR_VALUE'\n",
    "    \n",
    "    # updating output fields\n",
    "    output_fields += ['out_beg_match'] + ['out_end_match'] + ['out_year_overlap']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# adding the 'match_strength' column, leveraging the fact that Python True and False evaluate to 1 and 0 respectively when passed to int()\n",
    "df['out_content_match_strength'] = 0\n",
    "output_fields += ['out_content_match_strength']\n",
    "\n",
    "if ('input_x_coord' in incoming_fields):\n",
    "    if coord_mode == \"strict\":\n",
    "        df['out_content_match_strength'] += df['out_x_coord_match'].astype(int)\n",
    "    else: \n",
    "        df['out_content_match_strength'] += df['fuzzy_out_x_coord_match'].astype(int)\n",
    "\n",
    "if ('input_y_coord' in incoming_fields):\n",
    "    if coord_mode == \"strict\":\n",
    "        df['out_content_match_strength'] += df['out_y_coord_match'].astype(int)\n",
    "    else: \n",
    "        df['out_content_match_strength'] += df['fuzzy_out_y_coord_match'].astype(int)\n",
    "    \n",
    "if ('input_year_beg' in incoming_fields):\n",
    "    df['out_content_match_strength'] += df['out_beg_match'].astype(int) \n",
    "    \n",
    "if ('input_year_end' in incoming_fields):\n",
    "    df['out_content_match_strength'] += df['out_end_match'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# sorting columns\n",
    "#print(output_fields)\n",
    "ordered_fields = target_fields + incoming_fields + ['match'] + output_fields\n",
    "#print(ordered_fields)\n",
    "fuzzy_ordered_fields = ['fuzzy_nm'] + ordered_fields\n",
    "\n",
    "if name_mode == 'strict':\n",
    "    df = df[ordered_fields]\n",
    "else:\n",
    "    df = df[fuzzy_ordered_fields]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# replacing 'nan' with '' for improved legibility\n",
    "df = df.replace('nan', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data check is complete.  Please type a name (without extension) for your output files:\n",
      "\n",
      "160925test3\n",
      "Thank you. Saving results.\n",
      "\n",
      "Data output to 160925test3.csv \n",
      "Matching info and summary of results output to 160925test3.info.txt \n",
      "Now exiting\n"
     ]
    }
   ],
   "source": [
    "# outputting results\n",
    "print('\\nData check is complete.  Please type a name (without extension) for your output files:\\n')\n",
    "output_path = input()\n",
    "\n",
    "# TODO:  VALIDATE FILE NAME\n",
    "\n",
    "print(\"Thank you. Saving results.\")  \n",
    "\n",
    "# writing the file to the specified output path while dropping the unlabeled index column that pandas DataFrames generate by default\n",
    "df.to_csv(\"%s.csv\" % output_path, index=False)\n",
    "\n",
    "\n",
    "print(\"\\nData output to %s.csv \\nMatching info and summary of results output to %s.info.txt \\nNow exiting\" % (output_path, output_path))\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
