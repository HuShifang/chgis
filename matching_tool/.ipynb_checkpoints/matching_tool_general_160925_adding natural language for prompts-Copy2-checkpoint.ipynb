{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#! /usr/bin/python3\n",
    "\n",
    "# Script for comparing an input .csv file with an existing .csv file (e.g. the current CHGIS).\n",
    "# Indicates 1) matches on name and 2) strength of match on content\n",
    "# Requires the library 'pandas' to be installed, which is included in Anaconda's free Python distribution\n",
    "\n",
    "# by Stephen Ford (stephen.p.ford@gmail.com)\n",
    "\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import os.path\n",
    "\n",
    "# suppressing SettingWithCopyWarning\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Initializing the lists and dictionaries that will be used:\n",
    "# 1. to map the fields in the incoming and target .csv files to the standard output fields\n",
    "# 2. to drop the standard output fields that the user chooses not to use\n",
    "# 3. to put the final output fields into their desired, standard order\n",
    "\n",
    "# initializing list of incoming_fields \n",
    "incoming_fields = []\n",
    "\n",
    "# defining dictionary that stores the standard incoming field names along with a natural English description, for use in user prompts\n",
    "incoming_description = {\n",
    "    'input_id': 'a unique ID',\n",
    "    'input_nm_py':\"a name in pinyin\",\n",
    "    'input_nm_simp':\"a name in simplified Chinese characters (简体字)\",\n",
    "    'input_nm_trad':\"a name in traditional Chinese characters (繁體字)\",\n",
    "    'input_type_py':\"an administrative type in pinyin (e.g. 'Xian')\",\n",
    "    'input_type_ch':\"an administrative type in Chinese (simplified) characters (e.g. '县')\",\n",
    "    'input_year_beg':\"a beginning year\",\n",
    "    'input_year_end':\"an ending year\",\n",
    "    'input_dynasty':\"a dynasty\",\n",
    "    'input_other_id':\"another, alternate unique ID\",\n",
    "    'input_prnt':\"the parent administrative unit's name\",\n",
    "    'input_obj_type':\"a geospatial type (Point/Vector/Polygon)\",\n",
    "    'input_x_coord':\"an x coordinate\",\n",
    "    'input_y_coord':\"a y coordinate\"\n",
    "}\n",
    "\n",
    "# initializing dictionary that will store as key-value pairs the original .csv's fields and what they're renamed in the final output, respectively \n",
    "incoming_mapping = {}\n",
    "\n",
    "# declaring the list of output .csv field names that will derive from the new data\n",
    "# i.e., all those fields whose names will be 'input_*' in the final .csv\n",
    "final_incoming_fields = list(incoming_description.keys())\n",
    "\n",
    "# initializing list of actual target fields\n",
    "target_fields = []\n",
    "\n",
    "# initializing list of default CHGIS fields (taken from v5_augment_2016-08-09.csv)\n",
    "default_target_fields_v5 = [\n",
    "    'seq', \n",
    "    'sys_id', \n",
    "    'src', \n",
    "    'nm_py', \n",
    "    'nm_simp', \n",
    "    'nm_trad', \n",
    "    'x_coord', \n",
    "    'y_coord', \n",
    "    'pres_loc', \n",
    "    'type_py', \n",
    "    'type_ch', \n",
    "    'beg', \n",
    "    'end', \n",
    "    'obj_type',\n",
    "    'prnt_id', \n",
    "    'prnt_sysid', \n",
    "    'prnt_simp', \n",
    "    'prnt_py'\n",
    "]\n",
    "\n",
    "default_target_fields_v6 = [\n",
    " 'beg_rule',\n",
    " 'beg_type',\n",
    " 'beg_yr',\n",
    " 'checker',\n",
    " 'compiler',\n",
    " 'end_rule',\n",
    " 'end_type',\n",
    " 'end_yr',\n",
    " 'entry_date',\n",
    " 'filename',\n",
    " 'geo_comp',\n",
    " 'geo_src',\n",
    " 'level',\n",
    " 'mdb_id',\n",
    " 'nm_py',\n",
    " 'nm_simp',\n",
    " 'nm_trad',\n",
    " 'note_id',\n",
    " 'obj_type',\n",
    " 'orig_id',\n",
    " 'pres_loc',\n",
    " 'sys_id',\n",
    " 'type_py',\n",
    " 'type_simp',\n",
    " 'x_coord',\n",
    " 'y_coord'\n",
    "]\n",
    "\n",
    "\n",
    "target_description = {\n",
    "    'tgaz_sys_id':'a unique ID',\n",
    "    'tgaz_nm_py': \"a name in pinyin\",\n",
    "    'tgaz_nm_simp':\"a name in simplified Chinese characters (简体字)\",\n",
    "    'tgaz_nm_trad':\"a name in traditional Chinese characters (繁體字)\",\n",
    "    'tgaz_beg':\"a beginning year\",\n",
    "    'tgaz_end':\"an ending year\",\n",
    "    'tgaz_data_source': \"the source of the data\",\n",
    "    'tgaz_obj_type':\"a geospatial type (Point/Vector/Polygon)\",\n",
    "    'tgaz_pres_loc':\"the place's present-day name\",\n",
    "    'tgaz_prnt_id':\"the parent administrative unit's unique ID (NOT prefixed 'hvd_')\",\n",
    "    'tgaz_prnt_py':\"the parent administrative unit's name in pinyin\",\n",
    "    'tgaz_prnt_simp':\"the parent administrative unit's name in simplified Chinese characters (简体字)\",\n",
    "    'tgaz_prnt_sysid':\"the parent administrative unit's unique ID (prefxed 'hvd_')\",\n",
    "    'tgaz_type_ch':\"an administrative type in Chinese (simplified) characters (e.g. 县)\",\n",
    "    'tgaz_type_py':\"an administrative type in pinyin (e.g. 'Xian')\",\n",
    "    'tgaz_x_coord':\"an x coordinate\",\n",
    "    'tgaz_y_coord':\"a y coordinate\"\n",
    "}\n",
    "\n",
    "# initializing dictionary that will store as key-value pairs the original target .csv's fields and what they're renamed in the final output\n",
    "target_mapping = {}\n",
    "\n",
    "# initializing list of tgaz fields (i.e. the standardized output-form of the CHGIS fields)\n",
    "final_target_fields = list(target_description.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# function for selecting .csv files for manipulation\n",
    "\n",
    "def csv_picker():\n",
    "    ''' Function for checking whether user input path 1) is that of a valid file, and 2) is of a file ending with '.csv'\n",
    "        Prompts for re-entry if entry is invalid.\n",
    "        Returns a pandas DataFrame constructed from the valid .csv file\n",
    "    '''\n",
    "    path_name = input()\n",
    "\n",
    "    # checking that the path is a valid filename, and prompting for re-entry if not\n",
    "    while not (os.path.isfile(path_name)):\n",
    "        print(\"Not a valid filename.  Please try again:\")\n",
    "        path_name = input()\n",
    "        \n",
    "    # checking that the valid filename ends in .csv, prompting for re-entry if not\n",
    "    while not path_name.endswith('.csv'):\n",
    "        print(\"Filename does not end in .csv -- please try again:\")\n",
    "        path_name = input()\n",
    "\n",
    "    print(\"\\nThank you -- path %s is valid.\\n\" % path_name)\n",
    "    \n",
    "    # storing only the file's basename, for use in user prompts\n",
    "    name = os.path.basename(path_name)\n",
    "    return pd.read_csv(path_name, low_memory=False), name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# function for mapping the input .csv's fields to the desired, standardized output fields\n",
    "def field_mapper(std_field, std_field_description, frame, fields, name, mapping):\n",
    "    ''' Function that will prompt user to manually map fields of the input .csv to standardized output fields.\n",
    "        Name changes will be made in-place (i.e. in the DataFrame -- the .csv will be untouched).\n",
    "        If user fails to enter anything for the given mapping, that field will dropped from the final output file.        \n",
    "    '''\n",
    "    \n",
    "    print(\"\\nPlease enter the field of the incoming file %s that contains %s (this will be renamed '%s' in the output .csv:\" % (name, std_field_description, std_field))\n",
    "    orig_field = input()\n",
    "    \n",
    "    # prompts for re-entering the input field if 1) it is not one of the column names and 2) it isn't an empty string\n",
    "    while (not orig_field in list(frame.columns)) and (orig_field):\n",
    "        print(\"\\nNot a valid column name.  Please try again:\")\n",
    "        orig_field = input()\n",
    "        \n",
    "    # simply exit if the user pressed enter, bypassing the mapping, or perform the mapping if a valid field name has been entered\n",
    "    if orig_field:\n",
    "        mapping[orig_field] = std_field\n",
    "        frame.rename(columns={orig_field:std_field}, inplace=True)\n",
    "        fields += [std_field]\n",
    "    return fields, mapping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def name_checker(name_fields, fields, prefix, frame):\n",
    "    ''' Function will confirm that at least one name field has been entered, and prompt user to remap the three\n",
    "        name fields until at least one is a valid entry. Updates the DataFrame in-place and returns the updated field list.\n",
    "    '''\n",
    "    \n",
    "    while (((name_fields[0] in fields) or (name_fields[1] in fields) or (name_fields[2] in fields)) == False):\n",
    "        print(\"At least one name field needs to be specified. Please try again.\")\n",
    "        # counter ensures that name fields are inserted at correct place in sequence\n",
    "        counter = 1\n",
    "        for name_field in name_fields:\n",
    "            print(\"Please enter the field that will be labeled '%s' in the output .csv:\" % name_field)\n",
    "            orig_field = input()\n",
    "            if orig_field:\n",
    "                if (orig_field in list(frame.columns)):\n",
    "                    frame.rename(columns={orig_field:name_field}, inplace=True)\n",
    "                    fields.insert(counter, name_field)\n",
    "                    counter+=1\n",
    "                else: \n",
    "                    print(\"Input not accepted -- field not found in data.\")\n",
    "    return fields\n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# offering user choice of strict or fuzzy name-matching\n",
    "\n",
    "def merge_chooser(target_field, incoming_field):\n",
    "    ''' Function called only if the user selects to merge on traditional characters 繁體字 or simplified characters 简体字\n",
    "        Lets user choose whether to do a strict or fuzzy merge.\n",
    "        In a fuzzy merge, only the first two characters of the Chinese names will be checked against one another.\n",
    "    '''\n",
    "    print(\n",
    "    '''\n",
    "Please indicate, by entering a numerical digit 1-2, whether you wish to do a strict or fuzzy match of names:\n",
    "    1. Strict matching (e.g. '張掖' matches '張掖', but '張掖' does not match '張掖居延屬國')\n",
    "    2. Fuzzy matching (e.g. '張掖' matches '張掖', and '張掖' also matches '張掖居延屬國')\n",
    "    ''')\n",
    "\n",
    "    accepted = False\n",
    "    choice = input()\n",
    "\n",
    "    while accepted == False:\n",
    "        if choice == '1':\n",
    "            print('Proceeding with strict matching of names.')\n",
    "            accepted = True\n",
    "            mode = 'strict'\n",
    "            df = target.merge(incoming, how='outer', left_on=target_field, right_on=incoming_field, indicator=True)\n",
    "            return df, mode\n",
    "        elif choice == '2':\n",
    "            print('Proceeding with fuzzy matching of names.')\n",
    "            accepted = True\n",
    "            mode = 'fuzzy'\n",
    "            target['fuzzy_nm'] = target[target_field].map(lambda x: str(x)[:2])\n",
    "            incoming['fuzzy_nm'] = incoming[incoming_field].map(lambda x: str(x)[:2])\n",
    "            df = target.merge(incoming, how='outer', on='fuzzy_nm', indicator=True)\n",
    "            return df, mode\n",
    "        else:\n",
    "            print(\"\\nNot a valid response.  Please try again:\\n\")\n",
    "            choice = input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def coordinate_matcher(coords, frame, fields):\n",
    "    ''' Function that performs a strict or fuzzy matching of spatial coordinates.  Returns a string indicating the type of match performed.\n",
    "        The matches' results are added to the DataFrame within the function.\n",
    "    '''\n",
    "    \n",
    "    print(\n",
    "        '''\n",
    "    Please indicate, by entering a numerical digit 1-2, whether you wish to do a strict or fuzzy match of spatial coordinates:\n",
    "        1. Strict matching (requires exact match, e.g. '119.64656' does NOT match '119.646560', '119.64657', or '119.325')\n",
    "        2. Fuzzy matching (requires only that rounded numbers match -- you specify the number of decimal places)\n",
    "        ''')\n",
    "\n",
    "    accepted = False\n",
    "    choice = input()\n",
    "\n",
    "    while accepted == False:\n",
    "        if choice == '1':\n",
    "            print('Proceeding with strict matching of spatial coordinates.')\n",
    "            accepted = True\n",
    "            for coord in coords:\n",
    "                frame['out_%s_coord_match' % coord] = frame['input_%s_coord' % coord] == frame['tgaz_%s_coord' % coord]\n",
    "                fields += ['out_%s_coord_match' % coord]\n",
    "            return \"strict\"\n",
    "        elif choice == '2':\n",
    "            print(\"Proceeding with fuzzy matching of spatial coordinates.\")\n",
    "            accepted = True\n",
    "            print('''Please enter a number indicating the number of decimal places to which to round the decimal coordinate value.\n",
    "                      For example, if you enter 0, 117.91 and 118.08 will round to 118 and match; if you enter 1, 117.91 will round to 117.9 and 118.08 will round to 118.1, and they won't match.\n",
    "                      Be advised that coordinates rarely have more than 7 decimal places of precision.\n",
    "                  ''')\n",
    "            decimal_place = input()\n",
    "            try: \n",
    "                for coord in coords:\n",
    "                    frame['fuzzy_out_%s_coord_match' % coord] = frame['input_%s_coord' % coord].map(lambda x: round(x, int(decimal_place))) == frame['tgaz_%s_coord' % coord].map(lambda x: round(x, int(decimal_place)))\n",
    "                    fields += ['fuzzy_out_%s_coord_match' % coord]\n",
    "                return \"fuzzy\"\n",
    "                                                                                                \n",
    "            except:\n",
    "                print(\"Not a valid response. Defaulting to 0 (integer-rounding).\")\n",
    "                for coord in coords:\n",
    "                    frame['fuzzy_out_%s_coord_match' % coord] = frame['input_%s_coord' % coord].map(lambda x: round(x, 0)) == frame['tgaz_%s_coord' % coord].map(lambda x: round(x, 0))\n",
    "                    fields += ['fuzzy_out_%s_coord_match' % coord]\n",
    "                return \"fuzzy\" \n",
    "        else:\n",
    "            print(\"\\nNot a valid response.  Please try again:\\n\")\n",
    "            choice = input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def title_caser(fields, actual_fields, frame):\n",
    "    '''Very simple function that title-cases the contents of the given fields, provided that they are actually used in the DataFrame \n",
    "    '''   \n",
    "    for field in fields:\n",
    "        if field in actual_fields:\n",
    "            frame[field] = frame[field].map(lambda x: str(x).title())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# soliciting files for comparison; presumption is that second file entered will be the CHGIS v5 in .csv format\n",
    "#print(\"Please type the path of the incoming .csv file (with extension):\")\n",
    "#incoming, incoming_name = csv_picker()\n",
    "\n",
    "#print(\"Please type the path of the target .csv file (with extension):\")\n",
    "#target, target_name = csv_picker()\n",
    "\n",
    "\n",
    "### DEV ONLY\n",
    "# DongHan\n",
    "incoming = pd.read_csv(\"/home/sf/chgis/input/sample_data/Donghan_2014-10-02_copy.csv\", low_memory=False)\n",
    "incoming_name = \"Donghan_2014-10-02_copy.csv\"\n",
    "\n",
    "# /home/sf/chgis/input/sample_data/Donghan_2014-10-02_copy.csv\n",
    "# /home/sf/chgis/input/sample_data/lexdata.txt.data.csv\n",
    "\n",
    "\n",
    "# v5\n",
    "target = pd.read_csv(\"/home/sf/chgis/input/v5_augment_2016-08-09.csv\", low_memory=False)\n",
    "target_name = \"v5_augment_2016-08-09.csv\"\n",
    "\n",
    "\n",
    "# v6\n",
    "#target = pd.read_csv(\"/home/sf/chgis/input/V6_input_draft_20160811.csv\", low_memory=False)\n",
    "#target_name = \"V6_input_draft_20160811.csv\"\n",
    "# /home/sf/chgis/input/v5_augment_2016-08-09.csv\n",
    "# /home/sf/chgis/input/V6_input_draft_20160811.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'nm_py', 'src', 'x_coord', 'seq', 'pres_loc', 'obj_type', 'prnt_id', 'prnt_py', 'sys_id', 'nm_trad', 'nm_simp', 'beg', 'prnt_simp', 'type_ch', 'prnt_sysid', 'y_coord', 'end', 'type_py'}\n",
      "{'nm_py', 'src', 'x_coord', 'seq', 'pres_loc', 'obj_type', 'prnt_id', 'prnt_py', 'sys_id', 'nm_trad', 'nm_simp', 'beg', 'prnt_simp', 'type_ch', 'prnt_sysid', 'y_coord', 'end', 'type_py'}\n",
      "True\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(set(list(target.columns)))\n",
    "print(set(default_target_fields_v5))\n",
    "print(all(item in set(list(target.columns)) for item in set(default_target_fields_v5)))\n",
    "print(target_fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please indicate by entering '1' or '2' whether you wish to use a default mapping of CHGIS fields, or wish to manually map fields.\n",
      "    \n",
      "1. Use the default mapping -- presumes the target file has either of the following sets of columns:\n",
      "\n",
      "  CHGIS v5 standard fields:\n",
      "  ['seq', 'sys_id', 'src', 'nm_py', 'nm_simp', 'nm_trad', 'x_coord', 'y_coord', 'pres_loc', 'type_py', 'type_ch', 'beg', 'end', 'obj_type', 'prnt_id', 'prnt_sysid', 'prnt_simp', 'prnt_py']\n",
      "  \n",
      "  CHGIS v6 (Aug. 2016 draft) standard fields:\n",
      "  ['beg_rule', 'beg_type', 'beg_yr', 'checker', 'compiler', 'end_rule', 'end_type', 'end_yr', 'entry_date', 'filename', 'geo_comp', 'geo_src', 'level', 'mdb_id', 'nm_py', 'nm_simp', 'nm_trad', 'note_id', 'obj_type', 'orig_id', 'pres_loc', 'sys_id', 'type_py', 'type_simp', 'x_coord', 'y_coord']\n",
      "    \n",
      "\n",
      "2. Use a manual mapping -- you will be prompted to indicate which column from the file should map to which output column.\n",
      "\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "### presenting user with choice of a default mapping of CHGIS fields (based on v5_augment_2016-08-09.csv) or of manually entering their own mapping\n",
    "\n",
    "print('''Please indicate by entering '1' or '2' whether you wish to use a default mapping of CHGIS fields, or wish to manually map fields.\n",
    "    \n",
    "1. Use the default mapping -- presumes the target file has either of the following sets of columns:\n",
    "\n",
    "  CHGIS v5 standard fields:\n",
    "  %s\n",
    "  \n",
    "  CHGIS v6 (Aug. 2016 draft) standard fields:\n",
    "  %s\n",
    "    \n",
    "\n",
    "2. Use a manual mapping -- you will be prompted to indicate which column from the file should map to which output column.\n",
    "''' % (str(default_target_fields_v5), str(default_target_fields_v6)))\n",
    "\n",
    "accepted = False\n",
    "mapping = input()\n",
    "\n",
    "while accepted == False:\n",
    "    # checks them against one another using comparison of sets (which are collections of unordered, unique items)\n",
    "    if (mapping == '1'):\n",
    "        # if the default target fields from CHGIS v5 are a subset of the target's fields, rename and use them while dropping the fields not in CHGIS v5 \n",
    "        if all(item in set(list(target.columns)) for item in set(default_target_fields_v5)):\n",
    "            # manually renaming one exception to the following pattern\n",
    "            target.rename(columns={'src':'data_source'}, inplace=True)\n",
    "\n",
    "            # manually dropping the 'seq' field\n",
    "            del target['seq']\n",
    "            \n",
    "            # generating the target_mapping using a dictionary comprehension\n",
    "            target_mapping = {key:'tgaz_%s' % key for key in target.columns}\n",
    "            \n",
    "            # renaming the target fields in-place to conform to output specifications\n",
    "            #target.columns = list(target_mapping.values())\n",
    "            target.rename(columns={key:value for key,value in target_mapping.items()}, inplace=True)\n",
    "            \n",
    "            #target.columns = ['tgaz_%s' % x for x in target.columns]\n",
    "            \n",
    "            # dropping excess fields\n",
    "            target = target[final_target_fields]\n",
    "            target_fields = list(target.columns)\n",
    "            accepted = True\n",
    "      \n",
    "        # if the default target fields from CHGIS v6 are a subset of the target's fields, rename and use them while dropping the fields not in CHGIS v6\n",
    "        elif all(item in set(list(target.columns)) for item in set(default_target_fields_v6)):\n",
    "            # renaming in preparation for \"tgaz_\" prefixing\n",
    "            target.rename(columns={'geo_src':'data_source', 'type_simp':'type_ch', 'beg_yr':'beg', 'end_yr':'end' }, inplace=True)\n",
    "            \n",
    "            # dropping the difference of the two sets -- i.e. the fields that will not be used\n",
    "            # for item in (set(list(target.columns))\n",
    "            \n",
    "            target_mapping = {key:'tgaz_%s' % key for key in target.columns}\n",
    "            target.rename(columns={key:value for key,value in target_mapping.items()}, inplace=True)\n",
    "            #target.columns = list(target_mapping.values())\n",
    "            \n",
    "            # prefixing\n",
    "            #target.columns = ['tgaz_%s' % x for x in target.columns]\n",
    "            \n",
    "            # eliminating parent fields (since v6 data does not include parent information)\n",
    "            for parent_item in ['tgaz_prnt_id', 'tgaz_prnt_sysid', 'tgaz_prnt_simp', 'tgaz_prnt_py']:\n",
    "                final_target_fields.remove(parent_item) \n",
    "    \n",
    "            # dropping other excess fields\n",
    "            target = target[final_target_fields]\n",
    "            target_fields = list(target.columns)\n",
    "            accepted = True\n",
    "        \n",
    "        else: \n",
    "            # EDIT THE FOLLOWING TEXT\n",
    "            print(\"The columns in the selected CHGIS spreadsheet do not precisely match expectations. \\n\\n Proceeding with manual mapping.\")\n",
    "            for field, description in target_description.items():\n",
    "                target_fields, target_mapping = field_mapper(field, description, target, target_fields, target_name, target_mapping)  \n",
    "            target_fields = name_checker(['tgaz_nm_py', 'tgaz_nm_simp', 'tgaz_nm_trad'], target_fields, \"tgaz\", target)\n",
    "            target = target[target_fields]\n",
    "            accepted = True\n",
    "    elif (mapping == '2'):\n",
    "        print(\"Now, please specify fields from the CHGIS (match-receiving) data that will be included in the final spreadsheet.\\n\")\n",
    "        for field, description in target_description.items():\n",
    "            target_fields, target_mapping = field_mapper(field, description, target, target_fields, target_name, target_mapping)  \n",
    "        target_fields = name_checker(['tgaz_nm_py', 'tgaz_nm_simp', 'tgaz_nm_trad'], target_fields, \"tgaz\", target)\n",
    "        target = target[target_fields]\n",
    "        accepted = True\n",
    "    else:\n",
    "        print(\"\\nNot a valid response.  Please try again:\\n\")\n",
    "        mapping = input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tgaz_nm_trad', 'tgaz_beg', 'tgaz_prnt_py', 'tgaz_sys_id', 'tgaz_prnt_sysid', 'tgaz_type_ch', 'tgaz_y_coord', 'tgaz_pres_loc', 'tgaz_prnt_simp', 'tgaz_end', 'tgaz_prnt_id', 'tgaz_nm_py', 'tgaz_type_py', 'tgaz_nm_simp', 'tgaz_obj_type', 'tgaz_data_source', 'tgaz_x_coord']\n",
      "      tgaz_nm_trad  tgaz_beg   tgaz_prnt_py tgaz_sys_id tgaz_prnt_sysid  \\\n",
      "0               霸州      1820    Shuntian Fu       hvd_1        hvd_9513   \n",
      "1          正黃等四旗牧廠      1820  Koubeisanting       hvd_2        hvd_2065   \n",
      "2              定興縣      1820     Baoding Fu       hvd_3        hvd_9506   \n",
      "3              深澤縣      1820      Ding Zhou       hvd_4        hvd_9500   \n",
      "4              曲陽縣      1820      Ding Zhou       hvd_5        hvd_9500   \n",
      "5              棗強縣      1820        Ji Zhou       hvd_6        hvd_9501   \n",
      "6              武邑縣      1820        Ji Zhou       hvd_7        hvd_9501   \n",
      "7              南宮縣      1820        Ji Zhou       hvd_8        hvd_9501   \n",
      "8              衡水縣      1820        Ji Zhou       hvd_9        hvd_9501   \n",
      "9              新河縣      1820        Ji Zhou      hvd_10        hvd_9501   \n",
      "10             武強縣      1820      Shen Zhou      hvd_11        hvd_9502   \n",
      "11             饒陽縣      1820      Shen Zhou      hvd_12        hvd_9502   \n",
      "12             淶水縣      1820        Yi Zhou      hvd_13        hvd_9503   \n",
      "13             廣昌縣      1820        Yi Zhou      hvd_14        hvd_9503   \n",
      "14             柏鄉縣      1820      Zhao Zhou      hvd_15        hvd_9504   \n",
      "15             寧晉縣      1820      Zhao Zhou      hvd_16        hvd_9504   \n",
      "16             高邑縣      1820      Zhao Zhou      hvd_17        hvd_9504   \n",
      "17             隆平縣      1820      Zhao Zhou      hvd_18        hvd_9504   \n",
      "18             玉田縣      1820    Zunhua Zhou      hvd_19        hvd_9505   \n",
      "19             豐潤縣      1820    Zunhua Zhou      hvd_20        hvd_9505   \n",
      "20              唐縣      1820     Baoding Fu      hvd_21        hvd_9506   \n",
      "21             束鹿縣      1820     Baoding Fu      hvd_22        hvd_9506   \n",
      "22              蠡縣      1820     Baoding Fu      hvd_23        hvd_9506   \n",
      "23              祁州      1820     Baoding Fu      hvd_24        hvd_9506   \n",
      "24             高陽縣      1820     Baoding Fu      hvd_25        hvd_9506   \n",
      "25             滿城縣      1820     Baoding Fu      hvd_26        hvd_9506   \n",
      "26             清苑縣      1820     Baoding Fu      hvd_27        hvd_9506   \n",
      "27              雄縣      1820     Baoding Fu      hvd_28        hvd_9506   \n",
      "28             博野縣      1820     Baoding Fu      hvd_29        hvd_9506   \n",
      "29             安肅縣      1820     Baoding Fu      hvd_30        hvd_9506   \n",
      "...            ...       ...            ...         ...             ...   \n",
      "77739          綏定縣      1911        Yili Fu  hvd_198218      hvd_195525   \n",
      "77740          寧遠縣      1911        Yili Fu  hvd_198219      hvd_195525   \n",
      "77741        焉耆府本府      1911       Yanqi Fu  hvd_198220      hvd_195529   \n",
      "77742          輪台縣      1911       Yanqi Fu  hvd_198221      hvd_195529   \n",
      "77743          鄯善縣      1911   Tulufan Ting  hvd_198222      hvd_195522   \n",
      "77744          婼羌縣      1911       Yanqi Fu  hvd_198223      hvd_195529   \n",
      "77745          新平縣      1911       Yanqi Fu  hvd_198224      hvd_195529   \n",
      "77746        庫車州本州      1911     Kuche Zhou  hvd_198225      hvd_195530   \n",
      "77747          拜城縣      1911       Wensu Fu  hvd_198226      hvd_195528   \n",
      "77748          溫宿縣      1911       Wensu Fu  hvd_198227      hvd_195528   \n",
      "77749        溫宿府本府      1911       Wensu Fu  hvd_198228      hvd_195528   \n",
      "77750          沙雅縣      1911     Kuche Zhou  hvd_198229      hvd_195530   \n",
      "77751          疏附縣      1911       Shule Fu  hvd_198231      hvd_195532   \n",
      "77752        疏勒府本府      1911       Shule Fu  hvd_198232      hvd_195532   \n",
      "77753          伽師縣      1911       Shule Fu  hvd_198233      hvd_195532   \n",
      "77754          巴楚州      1911      Shache Fu  hvd_198234      hvd_195533   \n",
      "77755          於闐縣      1911    Hetian Zhou  hvd_198235      hvd_195534   \n",
      "77756          洛浦縣      1911    Hetian Zhou  hvd_198236      hvd_195534   \n",
      "77757        和闐州本州      1911    Hetian Zhou  hvd_198237      hvd_195534   \n",
      "77758          皮山縣      1911      Shache Fu  hvd_198238      hvd_195533   \n",
      "77759          葉城縣      1911      Shache Fu  hvd_198239      hvd_195533   \n",
      "77760        莎車府本府      1911      Shache Fu  hvd_198240      hvd_195533   \n",
      "77761          蒲犁廳      1911      Shache Fu  hvd_198242      hvd_195533   \n",
      "77762          中渡廳      1911      Guilin Fu  hvd_198243      hvd_195352   \n",
      "77763          奉天府      1664             \\N  hvd_201001              \\N   \n",
      "77764          奉天府      1876             \\N  hvd_201002              \\N   \n",
      "77765          奉天府      1877             \\N  hvd_201003              \\N   \n",
      "77766          奉天府      1902             \\N  hvd_201004              \\N   \n",
      "77767         瀋陽中衛      1386             \\N  hvd_201005              \\N   \n",
      "77768          平樂府      1369             \\N  hvd_201006              \\N   \n",
      "\n",
      "      tgaz_type_ch  tgaz_y_coord tgaz_pres_loc tgaz_prnt_simp  tgaz_end  \\\n",
      "0                州      39.10154          河北霸县            顺天府      1820   \n",
      "1               牧场      41.21478  内蒙古兴和县北大井洼东北           口北三厅      1820   \n",
      "2                县      39.26959         河北定兴县            保定府      1820   \n",
      "3                县      38.18490         河北深泽县             定州      1820   \n",
      "4                县      38.62145         河北曲阳县             定州      1820   \n",
      "5                县      37.50264         河北枣强县             冀州      1820   \n",
      "6                县      37.80599         河北武邑县             冀州      1820   \n",
      "7                县      37.35915         河北南宫市             冀州      1820   \n",
      "8                县      37.72616         河北衡水市             冀州      1820   \n",
      "9                县      37.52959         河北新河县             冀州      1820   \n",
      "10               县      37.99443    河北武强县西南武强镇             深州      1820   \n",
      "11               县      38.24599         河北饶阳县             深州      1820   \n",
      "12               县      39.39174         河北涞水县             易州      1820   \n",
      "13               县      39.35402         河北涞源县             易州      1820   \n",
      "14               县      37.49469         河北柏乡县             赵州      1820   \n",
      "15               县      37.62109         河北宁晋县             赵州      1820   \n",
      "16               县      37.60476         河北高邑县             赵州      1820   \n",
      "17               县      37.35228         河北隆尧县             赵州      1820   \n",
      "18               县      39.88367         河北玉田县            遵化州      1820   \n",
      "19               县      39.82760         河北玉田县            遵化州      1820   \n",
      "20               县      38.74149          河北唐县            保定府      1820   \n",
      "21               县      37.84853     河北束鹿县东南新城            保定府      1820   \n",
      "22               县      38.49006          河北蠡县            保定府      1820   \n",
      "23               州      38.41234         河北安国县            保定府      1820   \n",
      "24               县      38.68891         河北高阳县            保定府      1820   \n",
      "25               县      38.94772         河北满城县            保定府      1820   \n",
      "26               县      38.75659         河北保定市            保定府      1820   \n",
      "27               县      38.97588          河北雄县            保定府      1820   \n",
      "28               县      38.45757         河北博野县            保定府      1820   \n",
      "29               县      39.01944         河北徐水县            保定府      1820   \n",
      "...            ...           ...           ...            ...       ...   \n",
      "77739            县      44.05172           NaN            伊犁府      1911   \n",
      "77740            县      43.91536           NaN            伊犁府      1911   \n",
      "77741           本府       0.00000           NaN            焉耆府      1911   \n",
      "77742            县      41.77377           NaN            焉耆府      1911   \n",
      "77743            县      42.86079           NaN           吐鲁番厅      1911   \n",
      "77744            县      39.02064           NaN            焉耆府      1911   \n",
      "77745            县      41.33184           NaN            焉耆府      1911   \n",
      "77746           本州       0.00000           NaN            库车州      1911   \n",
      "77747            县      41.79325           NaN            温宿府      1911   \n",
      "77748            县      41.27287           NaN            温宿府      1911   \n",
      "77749           本府       0.00000           NaN            温宿府      1911   \n",
      "77750            县      41.21852           NaN            库车州      1911   \n",
      "77751            县      39.37560           NaN            疏勒府      1911   \n",
      "77752           本府       0.00000           NaN            疏勒府      1911   \n",
      "77753            县      39.49387           NaN            疏勒府      1911   \n",
      "77754            州      39.78678           NaN            莎车府      1911   \n",
      "77755            县      36.84896           NaN            和阗州      1911   \n",
      "77756            县      37.06603           NaN            和阗州      1911   \n",
      "77757           本州       0.00000           NaN            和阗州      1911   \n",
      "77758            县      37.61297           NaN            莎车府      1911   \n",
      "77759            县      37.88511           NaN            莎车府      1911   \n",
      "77760           本府       0.00000           NaN            莎车府      1911   \n",
      "77761            厅      37.77567           NaN            莎车府      1911   \n",
      "77762            厅      24.67461           NaN            桂林府      1911   \n",
      "77763            府       0.00000           NaN             \\N      1875   \n",
      "77764            府       0.00000           NaN             \\N      1876   \n",
      "77765            府       0.00000           NaN             \\N      1901   \n",
      "77766            府       0.00000           NaN             \\N      1911   \n",
      "77767            卫      41.78825         辽宁沈阳市             \\N      1643   \n",
      "77768            府       0.00000           NaN             \\N      1911   \n",
      "\n",
      "      tgaz_prnt_id                  tgaz_nm_py tgaz_type_py tgaz_nm_simp  \\\n",
      "0             2003                     Ba Zhou         zhou           霸州   \n",
      "1             1948  Zhenghuangdengsiqi Muchang     mu chang      正黄等四旗牧厂   \n",
      "2             1996                    Dingxing         xian          定兴县   \n",
      "3             1990                      Shenze         xian          深泽县   \n",
      "4             1990                      Quyang         xian          曲阳县   \n",
      "5             1991                    Zaoqiang         xian          枣强县   \n",
      "6             1991                        Wuyi         xian          武邑县   \n",
      "7             1991                     Nangong         xian          南宫县   \n",
      "8             1991                    Hengshui         xian          衡水县   \n",
      "9             1991                       Xinhe         xian          新河县   \n",
      "10            1992                     Wuqiang         xian          武强县   \n",
      "11            1992                     Raoyang         xian          饶阳县   \n",
      "12            1993                     Laishui         xian          涞水县   \n",
      "13            1993                  Guangchang         xian          广昌县   \n",
      "14            1994                    Baixiang         xian          柏乡县   \n",
      "15            1994                     Ningjin         xian          宁晋县   \n",
      "16            1994                       Gaoyi         xian          高邑县   \n",
      "17            1994                    Longping         xian          隆平县   \n",
      "18            1995                      Yutian         xian          玉田县   \n",
      "19            1995                     Fengrun         xian          丰润县   \n",
      "20            1996                   Tang Xian         xian           唐县   \n",
      "21            1996                       Shulu         xian          束鹿县   \n",
      "22            1996                     Li Xian         xian           蠡县   \n",
      "23            1996                     Qi Zhou         zhou           祁州   \n",
      "24            1996                     Gaoyang         xian          高阳县   \n",
      "25            1996                    Mancheng         xian          满城县   \n",
      "26            1996                    Qingyuan         xian          清苑县   \n",
      "27            1996                  Xiong Xian         xian           雄县   \n",
      "28            1996                        Boye         xian          博野县   \n",
      "29            1996                        Ansu         xian          安肃县   \n",
      "...            ...                         ...          ...          ...   \n",
      "77739        75772                Suiding Xian         xian          绥定县   \n",
      "77740        75772               Ningyuan Xian         xian          宁远县   \n",
      "77741        75776               Yanqifu Benfu       ben fu        焉耆府本府   \n",
      "77742        75776                 Luntai Xian         xian          轮台县   \n",
      "77743        75769               Shanshan Xian         xian          鄯善县   \n",
      "77744        75776               Ruoqiang Xian         xian          婼羌县   \n",
      "77745        75776                Xinping Xian         xian          新平县   \n",
      "77746        75777           Kuchezhou Benzhou     ben zhou        库车州本州   \n",
      "77747        75775               Baicheng Xian         xian          拜城县   \n",
      "77748        75775                  Wensu Xian         xian          温宿县   \n",
      "77749        75775               Wensufu Benfu       ben fu        温宿府本府   \n",
      "77750        75777                  Shaya Xian         xian          沙雅县   \n",
      "77751        75779                  Shufu Xian         xian          疏附县   \n",
      "77752        75779               Shulefu Benfu       ben fu        疏勒府本府   \n",
      "77753        75779                 Jiashi Xian         xian          伽师县   \n",
      "77754        75780                   Bachuzhou         zhou          巴楚州   \n",
      "77755        75781                 Yutian Xian         xian          于阗县   \n",
      "77756        75781                  Luopu Xian         xian          洛浦县   \n",
      "77757        75781          Hetianzhou Benzhou     ben zhou        和阗州本州   \n",
      "77758        75780                 Pishan Xian         xian          皮山县   \n",
      "77759        75780                Yecheng Xian         xian          叶城县   \n",
      "77760        75780              Shachefu Benfu       ben fu        莎车府本府   \n",
      "77761        75780                    Puliting         ting          蒲犁厅   \n",
      "77762        75623                Zhongdu Ting         ting          中渡厅   \n",
      "77763           \\N                 Fengtian Fu           fu          奉天府   \n",
      "77764           \\N                 Fengtian Fu           fu          奉天府   \n",
      "77765           \\N                 Fengtian Fu           fu          奉天府   \n",
      "77766           \\N                 Fengtian Fu           fu          奉天府   \n",
      "77767           \\N           Shenyang Zhongwei          wei         沈阳中卫   \n",
      "77768           \\N                   Pingle Fu           fu          平乐府   \n",
      "\n",
      "      tgaz_obj_type tgaz_data_source  tgaz_x_coord  \n",
      "0             POINT            CHGIS     116.39525  \n",
      "1             POINT            CHGIS     113.89422  \n",
      "2             POINT            CHGIS     115.77419  \n",
      "3             POINT            CHGIS     115.19209  \n",
      "4             POINT            CHGIS     114.69020  \n",
      "5             POINT            CHGIS     115.71808  \n",
      "6             POINT            CHGIS     115.89066  \n",
      "7             POINT            CHGIS     115.38007  \n",
      "8             POINT            CHGIS     115.70573  \n",
      "9             POINT            CHGIS     115.24651  \n",
      "10            POINT            CHGIS     115.85923  \n",
      "11            POINT            CHGIS     115.73602  \n",
      "12            POINT            CHGIS     115.70780  \n",
      "13            POINT            CHGIS     114.68877  \n",
      "14            POINT            CHGIS     114.68058  \n",
      "15            POINT            CHGIS     114.91540  \n",
      "16            POINT            CHGIS     114.61153  \n",
      "17            POINT            CHGIS     114.76604  \n",
      "18            POINT            CHGIS     117.75478  \n",
      "19            POINT            CHGIS     118.13490  \n",
      "20            POINT            CHGIS     114.96910  \n",
      "21            POINT            CHGIS     115.30855  \n",
      "22            POINT            CHGIS     115.57470  \n",
      "23            POINT            CHGIS     115.31509  \n",
      "24            POINT            CHGIS     115.77420  \n",
      "25            POINT            CHGIS     115.31562  \n",
      "26            POINT            CHGIS     115.48461  \n",
      "27            POINT            CHGIS     116.09270  \n",
      "28            POINT            CHGIS     115.45908  \n",
      "29            POINT            CHGIS     115.65739  \n",
      "...             ...              ...           ...  \n",
      "77739       POLYGON            CHGIS       0.00000  \n",
      "77740       POLYGON            CHGIS       0.00000  \n",
      "77741       POLYGON            CHGIS       0.00000  \n",
      "77742       POLYGON            CHGIS       0.00000  \n",
      "77743       POLYGON            CHGIS       0.00000  \n",
      "77744       POLYGON            CHGIS       0.00000  \n",
      "77745       POLYGON            CHGIS       0.00000  \n",
      "77746       POLYGON            CHGIS       0.00000  \n",
      "77747       POLYGON            CHGIS       0.00000  \n",
      "77748       POLYGON            CHGIS       0.00000  \n",
      "77749       POLYGON            CHGIS       0.00000  \n",
      "77750       POLYGON            CHGIS       0.00000  \n",
      "77751       POLYGON            CHGIS       0.00000  \n",
      "77752       POLYGON            CHGIS       0.00000  \n",
      "77753       POLYGON            CHGIS       0.00000  \n",
      "77754       POLYGON            CHGIS       0.00000  \n",
      "77755       POLYGON            CHGIS       0.00000  \n",
      "77756       POLYGON            CHGIS       0.00000  \n",
      "77757       POLYGON            CHGIS       0.00000  \n",
      "77758       POLYGON            CHGIS       0.00000  \n",
      "77759       POLYGON            CHGIS       0.00000  \n",
      "77760       POLYGON            CHGIS       0.00000  \n",
      "77761       POLYGON            CHGIS       0.00000  \n",
      "77762         POINT            CHGIS     109.69404  \n",
      "77763       POLYGON            CHGIS       0.00000  \n",
      "77764       POLYGON            CHGIS       0.00000  \n",
      "77765       POLYGON            CHGIS       0.00000  \n",
      "77766       POLYGON            CHGIS       0.00000  \n",
      "77767         POINT            CHGIS     123.41988  \n",
      "77768       POLYGON            CHGIS       0.00000  \n",
      "\n",
      "[77769 rows x 17 columns]\n"
     ]
    }
   ],
   "source": [
    "#print(target.columns)\n",
    "#print(target)\n",
    "#print(target['tgaz_nm_py'].dtype)\n",
    "print(target_fields)\n",
    "print(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now we will specify fields from the incoming (match-making) data that will be included in the final spreadsheet.\n",
      "\n",
      "\n",
      "Please enter the field of the incoming file Donghan_2014-10-02_copy.csv that contains an administrative type in Chinese (simplified) characters (e.g. '县') (this will be renamed 'input_type_ch' in the output .csv:\n",
      "\n",
      "\n",
      "Please enter the field of the incoming file Donghan_2014-10-02_copy.csv that contains a name in pinyin (this will be renamed 'input_nm_py' in the output .csv:\n",
      "\n",
      "\n",
      "Please enter the field of the incoming file Donghan_2014-10-02_copy.csv that contains an x coordinate (this will be renamed 'input_x_coord' in the output .csv:\n",
      "經度\n",
      "\n",
      "Please enter the field of the incoming file Donghan_2014-10-02_copy.csv that contains a unique ID (this will be renamed 'input_id' in the output .csv:\n",
      "規範碼\n",
      "\n",
      "Please enter the field of the incoming file Donghan_2014-10-02_copy.csv that contains a geospatial type (Point/Vector/Polygon) (this will be renamed 'input_obj_type' in the output .csv:\n",
      "\n",
      "\n",
      "Please enter the field of the incoming file Donghan_2014-10-02_copy.csv that contains a y coordinate (this will be renamed 'input_y_coord' in the output .csv:\n",
      "緯度\n",
      "\n",
      "Please enter the field of the incoming file Donghan_2014-10-02_copy.csv that contains a dynasty (this will be renamed 'input_dynasty' in the output .csv:\n",
      "朝代\n",
      "\n",
      "Please enter the field of the incoming file Donghan_2014-10-02_copy.csv that contains the parent administrative unit's name (this will be renamed 'input_prnt' in the output .csv:\n",
      "\n",
      "\n",
      "Please enter the field of the incoming file Donghan_2014-10-02_copy.csv that contains another, alternate unique ID (this will be renamed 'input_other_id' in the output .csv:\n",
      "\n",
      "\n",
      "Please enter the field of the incoming file Donghan_2014-10-02_copy.csv that contains a name in traditional Chinese characters (繁體字) (this will be renamed 'input_nm_trad' in the output .csv:\n",
      "县名\n",
      "\n",
      "Please enter the field of the incoming file Donghan_2014-10-02_copy.csv that contains a beginning year (this will be renamed 'input_year_beg' in the output .csv:\n",
      "BEG\n",
      "\n",
      "Please enter the field of the incoming file Donghan_2014-10-02_copy.csv that contains an administrative type in pinyin (e.g. 'Xian') (this will be renamed 'input_type_py' in the output .csv:\n",
      "\n",
      "\n",
      "Please enter the field of the incoming file Donghan_2014-10-02_copy.csv that contains an ending year (this will be renamed 'input_year_end' in the output .csv:\n",
      "END\n",
      "\n",
      "Please enter the field of the incoming file Donghan_2014-10-02_copy.csv that contains a name in simplified Chinese characters (简体字) (this will be renamed 'input_nm_simp' in the output .csv:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# renaming fields in the incoming DataFrame to conform to specifications\n",
    "\n",
    "print(\"Now we will specify fields from the incoming (match-making) data that will be included in the final spreadsheet.\\n\")\n",
    "for field, description in incoming_description.items():\n",
    "    incoming_fields, incoming_mapping = field_mapper(field, description, incoming, incoming_fields, incoming_name, incoming_mapping)    \n",
    "\n",
    "incoming_fields = name_checker(['input_nm_py', 'input_nm_simp', 'input_nm_trad'], incoming_fields, \"input\", incoming)\n",
    "incoming = incoming[incoming_fields]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### titlecasing string values in pinyin fields to avoid spurious mismatches; could be refactored later\n",
    "\n",
    "#for field in ['tgaz_nm_py', 'tgaz_type_py']:\n",
    "#    if field in target_fields:\n",
    "#        target[field] = target[field].map(lambda x: str(x).title())\n",
    "        \n",
    "#for field in ['input_nm_py', 'input_type_py']:\n",
    "#    if field in incoming_fields:\n",
    "#        incoming[field] = incoming[]\n",
    "#target['tgaz_nm_py'] = target['tgaz_nm_py'].map(lambda x: str(x).title())\n",
    "#target['tgaz_type_py'] = target['tgaz_type_py'].map(lambda x: str(x).title())\n",
    "#incoming['input_nm_py'] = incoming['input_nm_py'].map(lambda x: str(x).title())\n",
    "#incoming['input_type_py'] = incoming['input_nm_py'].map(lambda x: str(x).title())\n",
    "\n",
    "title_caser(['tgaz_nm_py', 'tgaz_type_py'], target_fields, target)\n",
    "title_caser(['input_nm_py', 'input_type_py'], incoming_fields, incoming)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Thank you. Now, please indicate, by entering a numerical digit 1-3, which of the following names you wish to make the primary key for comparing data:\n",
      "    1. Name in complex/traditional Chinese characters 繁体字\n",
      "    2. Name in simplified Chinese characters 简体字\n",
      "    3. Name in pinyin 拼音\n",
      "    \n",
      "1\n",
      "\n",
      "Using name in complex/traditional Chinese characters 繁体字 as primary matching key.\n",
      "\n",
      "Please indicate, by entering a numerical digit 1-2, whether you wish to do a strict or fuzzy match of names:\n",
      "    1. Strict matching (e.g. '張掖' matches '張掖', but '張掖' does not match '張掖居延屬國')\n",
      "    2. Fuzzy matching (e.g. '張掖' matches '張掖', and '張掖' also matches '張掖居延屬國')\n",
      "    \n",
      "2\n",
      "Proceeding with fuzzy matching of names.\n"
     ]
    }
   ],
   "source": [
    "# soliciting user choice regarding which name field to take as primary\n",
    "print(\n",
    "    '''\n",
    "Thank you. Now, please indicate, by entering a numerical digit 1-3, which of the following names you wish to make the primary key for comparing data:\n",
    "    1. Name in complex/traditional Chinese characters 繁体字\n",
    "    2. Name in simplified Chinese characters 简体字\n",
    "    3. Name in pinyin 拼音\n",
    "    '''\n",
    ")\n",
    "\n",
    "accepted = False\n",
    "choice = input()\n",
    "\n",
    "while accepted == False:\n",
    "    if ((choice == '1') and ('input_nm_trad' in incoming_fields)):\n",
    "        print(\"\\nUsing name in complex/traditional Chinese characters 繁体字 as primary matching key.\")\n",
    "        accepted = True\n",
    "        incoming_name_match_field = 'input_nm_trad'\n",
    "        target_name_match_field = 'tgaz_nm_trad'\n",
    "        df, name_mode = merge_chooser(target_name_match_field, incoming_name_match_field)\n",
    "    elif ((choice == '2') and ('input_nm_simp' in incoming_fields)):\n",
    "        print(\"\\nUsing name in simplified Chinese characters 简体字 as primary matching key.\")\n",
    "        accepted = True\n",
    "        incoming_name_match_field = 'input_nm_simp'\n",
    "        target_name_match_field = 'tgaz_nm_simp'\n",
    "        df, name_mode = merge_chooser(target_name_match_field, incoming_name_match_field)\n",
    "    elif ((choice == '3') and ('input_nm_py' in incoming_fields)):\n",
    "        print(\"\\nUsing name in pinyin 拼音 as primary matching key.\")\n",
    "        accepted = True\n",
    "        incoming_name_match_field = 'input_nm_py'\n",
    "        target_name_match_field = 'tgaz_nm_py'\n",
    "        name_mode = 'strict'\n",
    "        print('Fuzzy matching is not currently supported for pinyin names.  Proceeding with strict matching.')\n",
    "        df = target.merge(incoming, how='outer', left_on=target_name_match_field, right_on=incoming_name_match_field, indicator=True)\n",
    "        \n",
    "    else:\n",
    "        print(\"\\nNot a valid response.  Please try again, entering a choice corresponding to a valid field:\\n\")\n",
    "        choice = input()\n",
    "        \n",
    "output_fields = []            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# removing rows that are only present in the CHGIS file\n",
    "df = df[df['_merge'] != 'left_only']\n",
    "\n",
    "# renaming merge indicators for legibility\n",
    "df = df.replace(to_replace='both', value='found')\n",
    "df = df.replace(to_replace='right_only', value='not_found')\n",
    "df.rename(columns={'_merge':'match'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in the for loop\n",
      "converting input_x_coord\n",
      "in the for loop\n",
      "converting input_y_coord\n",
      "in the for loop\n",
      "converting tgaz_x_coord\n",
      "in the for loop\n",
      "converting tgaz_y_coord\n",
      "\n",
      "    Please indicate, by entering a numerical digit 1-2, whether you wish to do a strict or fuzzy match of spatial coordinates:\n",
      "        1. Strict matching (requires exact match, e.g. '119.64656' does NOT match '119.646560', '119.64657', or '119.325')\n",
      "        2. Fuzzy matching (requires only that rounded numbers match -- you specify the number of decimal places)\n",
      "        \n",
      "2\n",
      "Proceeding with fuzzy matching of spatial coordinates.\n",
      "Please enter a number indicating the number of decimal places to which to round the decimal coordinate value.\n",
      "                      For example, if you enter 0, 117.91 and 118.08 will round to 118 and match; if you enter 1, 117.91 will round to 117.9 and 118.08 will round to 118.1, and they won't match.\n",
      "                      Be advised that coordinates rarely have more than 7 decimal places of precision.\n",
      "                  \n",
      "2\n"
     ]
    }
   ],
   "source": [
    "#### Abandoning comprehensive for-loop for sake of year matching; manually stringifying coords instead\n",
    "\n",
    "# converting all fields to strings for ease of comparison\n",
    "#for field in list(df.columns):\n",
    "#    df[field] = df[field].astype(str)\n",
    "spatial_coords = ['input_x_coord', 'input_y_coord', 'tgaz_x_coord', 'tgaz_y_coord']\n",
    "\n",
    "# converting the given field's values to a numeric, or NaN, for possible rounding later\n",
    "try: \n",
    "    for field in spatial_coords:\n",
    "        print(\"in the for loop\")\n",
    "        if (field in incoming_fields) or (field in target_fields):\n",
    "            print(\"converting %s\" % field)\n",
    "            df[field] = pd.to_numeric(df[field], errors='coerce')\n",
    "    if ('input_x_coord' in incoming_fields) and ('input_y_coord' in incoming_fields):\n",
    "        coord_mode = coordinate_matcher(['x', 'y'], df, output_fields)\n",
    "    elif ('input_x_coord' in incoming_fields) and not ('input_y_coord' in incoming_fields):\n",
    "        coord_mode = coordinate_matcher(['x'], df, output_fields)\n",
    "    elif not ('input_x_coord' in incoming_fields) and ('input_y_coord' in incoming_fields):\n",
    "        coord_mode = coordinate_matcher(['y'], df, output_fields)\n",
    "    else:\n",
    "        print(\"\\nNo spatial coordinate fields available for matching.\")\n",
    "except KeyError:\n",
    "    print(\"Spatial coordinates not properly entered. Skipping coordinate matching.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Administrative type (e.g. 'Xian' or '县') could not be found in incoming data -- matching will not be attempted.\n"
     ]
    }
   ],
   "source": [
    "### handling administrative type matching\n",
    "if ('input_type_ch' in incoming_fields) and ('input_type_py' in incoming_fields):\n",
    "    print('''Administrative type information found in incoming data. Input the number for the field you want to match on:\n",
    "        1. Pinyin ('Xian', 'Zhou', etc)\n",
    "        2. Chinese ('县', '州', etc)\n",
    "    ''')\n",
    "    \n",
    "    type_choice = input()\n",
    "    accepted = False\n",
    "    \n",
    "    while accepted == False:\n",
    "        if (type_choice) == '1':\n",
    "            df['out_type_py_match'] = df['tgaz_type_py'] == df['input_type_py']\n",
    "            accepted = True\n",
    "        elif type_choice == '2':\n",
    "            df['out_type_ch_match'] = df['tgaz_type_ch'] == df['input_type_ch']\n",
    "            accepted = True\n",
    "        else:\n",
    "            print('Not a valid choice, please try again:')\n",
    "            type_choice = input()\n",
    "            \n",
    "elif ('input_type_ch' in incoming_fields) and ('input_type_py' not in incoming_fields):\n",
    "    print(\"The field 'input_type_py' could not be found; matching administrative type on field 'input_type_ch'\")\n",
    "    df['out_type_ch_match'] = df['tgaz_type_ch'] == df['input_type_ch']\n",
    "    \n",
    "elif ('input_type_py' in incoming_fields) and ('input_type_ch' not in incoming_fields):\n",
    "    print(\"The field 'input_type_ch' could not be found; matching administrative type on field 'input_type_py'\")\n",
    "    df['out_type_py_match'] = df['tgaz_type_py'] == df['input_type_py']\n",
    "    \n",
    "else:\n",
    "    print(\"Administrative type (e.g. 'Xian' or '县') could not be found in incoming data -- matching will not be attempted.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "############## NEW ################\n",
    "#if (df['input_year_beg'].empty() | df['input_year_end'].empty()):\n",
    "#    if (df['input_year_beg'].empty()):\n",
    "#        df.drop(['input_year_beg'])\n",
    "#        input_fields.remove('input_year_beg')\n",
    "#        beg_year_matching = False\n",
    "#    if (df['input_year_end'].empty()):\n",
    "#        df.drop(['input_year_end'])\n",
    "#        input_fields.remove('input_year_end')\n",
    "#        end_year_matching = False\n",
    "\n",
    "if (not 'input_year_beg' in incoming_fields) or (not 'input_year_end' in incoming_fields):\n",
    "    print(\"Incoming data lacks a beginning and/or ending year field; no date comparisons will be made.\")\n",
    "else:\n",
    "    # beg_year_matching, end_year_matching = True, True\n",
    "    \n",
    "    year_fields = ['input_year_beg', 'input_year_end', 'tgaz_beg', 'tgaz_end']\n",
    "    \n",
    "    #for field in year_fields:\n",
    "    #    print(df[field].dtype)\n",
    "           \n",
    "    # overlap field initialization\n",
    "    df['out_year_overlap'] = ''\n",
    "\n",
    "           \n",
    "    # converting to type float64 (invalid years become 'NaN', and pandas.isnull(<Series_(column)>) returns True for those values\n",
    "    for year_field in year_fields:\n",
    "        df[year_field] = pd.to_numeric(df[year_field], errors='coerce')\n",
    "    \n",
    "    # in-row match testing\n",
    "    df['out_beg_match'] = df['input_year_beg'] == df['tgaz_beg']\n",
    "    df['out_end_match'] = df['input_year_end'] == df['tgaz_end']\n",
    "    \n",
    "    # testing for timespan relationships\n",
    "    df['out_year_overlap'][((df['input_year_beg'] == (df['tgaz_end'] + 1)) | (df['input_year_end'] == (df['tgaz_beg'] - 1)))] = 'adjacent'\n",
    "    df['out_year_overlap'][(df['input_year_beg'] <= df['tgaz_beg']) & (df['input_year_end'] >= df['tgaz_beg']) & (df['input_year_end'] < df['tgaz_end'])] = 'partial_incl_start_of_target'\n",
    "    df['out_year_overlap'][(df['input_year_beg'] > df['tgaz_beg']) & (df['input_year_beg'] <= df['tgaz_end']) & (df['input_year_end'] >= df['tgaz_end'])] = 'partial_incl_end_of_target'\n",
    "    df['out_year_overlap'][((df['input_year_beg'] >= df['tgaz_beg']) & (df['input_year_end'] < df['tgaz_end'])) | ((df['input_year_beg'] > df['tgaz_beg']) & (df['input_year_end'] <= df['tgaz_end']))] = 'incoming_nested_in_target'\n",
    "    df['out_year_overlap'][((df['input_year_beg'] <= df['tgaz_beg']) & (df['input_year_end'] > df['tgaz_end']) | (df['input_year_beg'] < df['tgaz_beg']) & (df['input_year_end'] >= df['tgaz_end']))] = 'target_nested_in_incoming'\n",
    "    df['out_year_overlap'][(df['input_year_beg'] == df['tgaz_beg']) & (df['input_year_end'] == df['tgaz_end'])] = 'perfect_match'\n",
    "    df['out_year_overlap'][(df['input_year_beg'] == 0) | (df['input_year_end'] == 0) | (df['tgaz_beg'] == 0) | (df['tgaz_end'] == 0)] = 'CAUTION__ZEROES'\n",
    "    df['out_year_overlap'][(df['input_year_beg'] > df['input_year_end']) | (df['tgaz_beg'] > df['tgaz_end'])] = 'ERROR__END_BEFORE_BEG'\n",
    "    \n",
    "    # designating items with non-numeric text values in at least one year field (which therefore break the overlap checker)\n",
    "    df['out_year_overlap'][(df['match'] == 'found') & (pd.isnull(df['input_year_beg']) | pd.isnull(df['input_year_end']) | pd.isnull(df['tgaz_beg']) | pd.isnull(df['tgaz_end']))] = 'ERROR__NON_NUMERIC_YEAR_VALUE'\n",
    "    \n",
    "    # updating output fields\n",
    "    output_fields += ['out_beg_match'] + ['out_end_match'] + ['out_year_overlap']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# adding the 'match_strength' column, leveraging the fact that Python True and False evaluate to 1 and 0 respectively when passed to int()\n",
    "df['out_content_match_strength'] = 0\n",
    "output_fields += ['out_content_match_strength']\n",
    "\n",
    "if ('input_x_coord' in incoming_fields):\n",
    "    if coord_mode == \"strict\":\n",
    "        df['out_content_match_strength'] += df['out_x_coord_match'].astype(int)\n",
    "    else: \n",
    "        df['out_content_match_strength'] += df['fuzzy_out_x_coord_match'].astype(int)\n",
    "\n",
    "if ('input_y_coord' in incoming_fields):\n",
    "    if coord_mode == \"strict\":\n",
    "        df['out_content_match_strength'] += df['out_y_coord_match'].astype(int)\n",
    "    else: \n",
    "        df['out_content_match_strength'] += df['fuzzy_out_y_coord_match'].astype(int)\n",
    "    \n",
    "for field in ['out_beg_match', 'out_end_match', 'out_type_ch_match', 'out_type_py_match']:\n",
    "    if field in list(df.columns):\n",
    "        df['out_content_match_strength'] += df[field].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tgaz_nm_trad', 'tgaz_beg', 'tgaz_prnt_py', 'tgaz_sys_id', 'tgaz_prnt_sysid', 'tgaz_type_ch', 'tgaz_y_coord', 'tgaz_pres_loc', 'tgaz_prnt_simp', 'tgaz_end', 'tgaz_prnt_id', 'tgaz_nm_py', 'tgaz_type_py', 'tgaz_nm_simp', 'tgaz_obj_type', 'tgaz_data_source', 'tgaz_x_coord']\n",
      "['input_x_coord', 'input_id', 'input_y_coord', 'input_dynasty', 'input_nm_trad', 'input_year_beg', 'input_year_end']\n",
      "['fuzzy_out_x_coord_match', 'fuzzy_out_y_coord_match', 'out_beg_match', 'out_end_match', 'out_year_overlap', 'out_content_match_strength']\n"
     ]
    }
   ],
   "source": [
    "print(target_fields)\n",
    "print(incoming_fields)\n",
    "print(output_fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# sorting columns\n",
    "#print(output_fields)\n",
    "ordered_fields = target_fields + incoming_fields + ['match'] + output_fields\n",
    "#print(ordered_fields)\n",
    "fuzzy_ordered_fields = ['fuzzy_nm'] + ordered_fields\n",
    "\n",
    "if name_mode == 'strict':\n",
    "    df = df[ordered_fields]\n",
    "else:\n",
    "    df = df[fuzzy_ordered_fields]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# replacing 'nan' with '' for improved legibility\n",
    "df = df.replace('nan', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data check is complete.  Please type a path (without extension) for your output files:\n",
      "\n",
      "160925test7\n",
      "Thank you. Saving results.\n",
      "\n",
      "Files saved to the folder  \n",
      "\n",
      "Match results stored in 160925test7.csv \n",
      "\n",
      " Matching info and summary of results stored in 160925test7.info.txt \n",
      "\n",
      "Now exiting.\n"
     ]
    }
   ],
   "source": [
    "# outputting results\n",
    "print('\\nData check is complete.  Please type a path (without extension) for your output files:\\n')\n",
    "output_path = input()\n",
    "accepted = False\n",
    "\n",
    "# validating output_path\n",
    "#while accepted == False:\n",
    "    # CHECK THAT FILENAMES DON'T ALREADY EXIST\n",
    "    # CHECK THAT PATH IS VALID\n",
    "\n",
    "print(\"Thank you. Saving results.\")  \n",
    "\n",
    "# writing the DataFrame to a .csv file at the specified output path while dropping the unlabeled index column that pandas DataFrames generate by default\n",
    "df.to_csv(\"%s.csv\" % output_path, index=False)\n",
    "\n",
    "# creating the summary .info.txt file\n",
    "summary_file = open(\"%s.info.txt\" % output_path, \"w\")\n",
    "\n",
    "# writing boilerplate \n",
    "summary_file.write(\"GEONAME MATCH SUMMARY OF RESULTS\\n\\n\")\n",
    "\n",
    "# writing information about match\n",
    "summary_file.write(\"Report created at %s \\n\" % str(datetime.now)) \n",
    "summary_file.write(\"The incoming file %s was compared with the target file %s.\\n\" % (incoming_name, target_name))\n",
    "summary_file.write(\"The target file's fields were renamed as follows:\\n \\t\\t %s\\n\" % target_mapping)\n",
    "summary_file.write(\"The incoming file's fields were renamed as follows:\\n \\t\\t %s\\n\" % incoming_mapping)\n",
    "\n",
    "# closing file\n",
    "summary_file.close()\n",
    "\n",
    "print(\"\\nFiles saved to the folder %s \\n\\nMatch results stored in %s.csv \\n\\n Matching info and summary of results stored in %s.info.txt \\n\\nNow exiting.\" % (os.path.dirname(output_path), os.path.basename(output_path), os.path.basename(output_path)))\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
