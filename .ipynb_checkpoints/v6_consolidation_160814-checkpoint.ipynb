{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#! /usr/bin/python3\n",
    "\n",
    "# /v6_consolidation_160814.ipynb\n",
    "# /py_scripts/v6_consolidation_160814.py\n",
    "\n",
    "# A script for consolidating .csv files extracted from a Microsoft Access (.mdb) file containing CHGIS v6 data provided by Fudan University 复旦大学 \n",
    "# There are two .csv files being consolidated: one contains the full contents of the original .mdb file's GISInfoTable, and the other contains only those elements in the .mdb file's MainTable that did not exist in GISInfoTable.\n",
    "# These files ultimately trace back to the quick-and-dirty script work in /v6_internal_consistency_check_160811.ipynb and the .py script of the same name, but additional manipulation had been done on that script's output using LibreOffice\n",
    "# This script's output forms half of the basis for version_merge_160822.ipynb \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import DataFrame, Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import .csv files as dataframes \n",
    "v6_GISInfo = pd.read_csv('input/v6_GISInfoTable_2016-08-09.csv', low_memory=False)\n",
    "v6_Main_only = pd.read_csv('input/MainTable_and_not_GISInfoTable.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def progress_check(df, name):\n",
    "    '''function for exporting dataframes to .csv files, for progress-checking'''\n",
    "    df.to_csv('TESTING_%s.csv' % name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/sf/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/sf/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/sf/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/sf/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/sf/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "# append all the rows that had IDs in MainTable that aren't in the original GISInfoTable\n",
    "# Rule: where bou_id and pt_id are the same, if x&y are empty or =0s, use bou_id and set type to POLYGON\n",
    "#           ...if x&y !=0, use PT_ID and set as POINT object types\n",
    "\n",
    "# generating DataFrame of \"normal\" ('BOU_ID'==0), point items from MainTableOnly\n",
    "mask_normal = v6_Main_only['BOU_ID'] == 0\n",
    "Main_normal = v6_Main_only[mask_normal]\n",
    "Main_normal['orig_id'] = Main_normal['PT_ID']\n",
    "Main_normal['obj_type'] = 'POINT'\n",
    "\n",
    "# preparing DataFrame of \"abnormal\" ('BOU_ID' == 'PT_ID') rows from MainTableOnly\n",
    "mask_abnormal = v6_Main_only['BOU_ID'] == v6_Main_only['PT_ID']\n",
    "Main_abnormal = v6_Main_only[mask_abnormal]\n",
    "\n",
    "# generating DataFrame of polygon rows from abnormal rows from MainTableOnly\n",
    "mask_polygons = Main_abnormal['X_COOR'] == 0\n",
    "Main_abnormal_polygons = Main_abnormal[mask_polygons]\n",
    "Main_abnormal_polygons['orig_id'] = Main_abnormal_polygons['BOU_ID']\n",
    "Main_abnormal_polygons['obj_type'] = 'POLYGON'\n",
    "\n",
    "# generating DataFrame of point rows from abnormal rows from MainTableOnly\n",
    "# TODO: SEE IF THIS CAN BE DRY-ED OUT AND COMBINED WITH THE ABOVE Main_normal STUFF\n",
    "mask_points = Main_abnormal['X_COOR'] != 0\n",
    "Main_abnormal_points = Main_abnormal[mask_points]\n",
    "Main_abnormal_points['orig_id'] = Main_abnormal_points['PT_ID']\n",
    "Main_abnormal_points['obj_type'] = 'POINT'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# merging back together processed parts of the MainOnlyTable\n",
    "v6_Main_only_processed = pd.concat([Main_normal, Main_abnormal_polygons, Main_abnormal_points])\n",
    "# renaming columns in the MainTableOnly to match GISInfoTable\n",
    "v6_Main_only_processed = v6_Main_only_processed.rename(columns={'NAME_PY': 'nm_py', \n",
    "                               'NAME_CH':'nm_simp', \n",
    "                               'NAME_FT':'nm_trad', \n",
    "                               'PRES_LOC':'pres_loc', \n",
    "                               'BEG_CHG_TY':'beg_type', \n",
    "                               'END_CHG_TY':'end_type', \n",
    "                               'TYPE_PY':'type_py',\n",
    "                               'TYPE_CH':'type_simp',\n",
    "                               'LEV_RANK':'level',\n",
    "                               'BEG_YR':'beg_yr',\n",
    "                               'END_YR':'end_yr',\n",
    "                               'X_COOR':'x_coord',\n",
    "                               'Y_COOR':'y_coord'\n",
    "                              })\n",
    "# eliminating columns to be dropped in concatenation of DataFrames\n",
    "v6_Main_only_processed.drop(['BOU_ID', 'BOU_ID_EQUALS_PT_ID','BOU_ID_IN_GISINFO_SYS_ID','BOU_NOTE_ID','ISSUE?','PT_ID', 'PT_ID_IN_GISINFO_SYS_ID', 'PT_NOTE_ID', 'Unnamed: 0'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Adding 'sys_id' field that consists of 'hvd_' plus 'orig_id' value\n",
    "v6_Main_only_processed['sys_id'] = 'hvd_' + v6_Main_only_processed['orig_id'].astype(str)\n",
    "progress_check(v6_Main_only_processed, '160814_experiment') # PASS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# joining together GISInfoTable and v6_Main_only_processed\n",
    "v6_all = pd.concat([v6_GISInfo, v6_Main_only_processed])\n",
    "# progress_check(v6_all, 'v6_all') # LOOKS GOOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# name the result of the union of the v6 GISInfoTable and MainTable \"V6_input_draft_20160811.csv\"\n",
    "v6_all.to_csv('output/V6_input_draft_20160811.csv')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
